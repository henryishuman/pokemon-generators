{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pok√©mon Sprite Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import time\n",
    "import random as rand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Markov Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ascii text and convert to list\n",
    "filename = \"img_data/pokemon_jelly.txt\"\n",
    "raw_jelly = open(filename).read()\n",
    "raw_chars = list(raw_jelly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_prior_chars(n, char_index, chars):\n",
    "    return tuple([chars[char_index-n+i] for i in range(n)])\n",
    "\n",
    "def generate_char_mappings(raw_chars, n):\n",
    "    char_mappings = {}\n",
    "    for i in range(n,len(raw_chars)):\n",
    "        n_gram = get_n_prior_chars(n, i, raw_chars)\n",
    "        char = raw_chars[i]\n",
    "        if(n_gram in char_mappings):\n",
    "            char_mappings[n_gram] += [char]\n",
    "        else:\n",
    "            char_mappings[n_gram] = [char]\n",
    "    return char_mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_line_break_ngrams (char_mappings):\n",
    "    return [key for key in char_mappings.keys() if '\\n' in key[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_image_data(char_mappings):\n",
    "    line_break_mappings = get_all_line_break_ngrams(char_mappings)\n",
    "    current_ngram = rand.choice(line_break_mappings)\n",
    "    image_data = []#; image_data.extend(current_ngram)\n",
    "\n",
    "    while current_ngram in char_mappings and len(image_data)<56*56:\n",
    "        next_first_char = rand.choice(char_mappings[current_ngram])\n",
    "        current_ngram = current_ngram[1:] + tuple([next_first_char])\n",
    "        image_data.append(current_ngram[-1])\n",
    "\n",
    "    return image_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_image(image_data):\n",
    "    int_colors = {'\\n': (255,0,0), '3': (0,0,0), '2': (85,85,85), '1': (170,170,170), '0': (255,255,255)}\n",
    "    img = Image.new('RGB', (56, 56), color = 'white')\n",
    "    pixel_data = img.load()\n",
    "\n",
    "    timestamp = time.time()\n",
    "    for ix in range(len(image_data)):\n",
    "        pixel_data[ix%56, ix//56] = int_colors[image_data[ix]]\n",
    "    img.save('generated_img/markov/new_mon-{}.png'.format(timestamp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(2,56):\n",
    "    char_mappings = generate_char_mappings(raw_chars, n)\n",
    "    image_data = generate_image_data(char_mappings)\n",
    "    generate_image(image_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Average of Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ascii text and convert to list\n",
    "filename = \"img_data/pokemon_jelly.txt\"\n",
    "images = open(filename).read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_mon = [0 for i in range(56 * 56)]\n",
    "for image in images:\n",
    "    for i in range(len(image)):\n",
    "        average_mon[i] += int(image[i])\n",
    "\n",
    "for i in range(len(average_mon)):\n",
    "    average_mon[i] = int(average_mon[i] / len(images) * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_colors = {3: (0,0,0), 2: (85,85,85), 1: (170,170,170), 0: (255,255,255)}\n",
    "img = Image.new('RGB', (56, 56), color = 'white')\n",
    "pixel_data = img.load()\n",
    "\n",
    "timestamp = time.time()\n",
    "for ix in range(len(average_mon)):\n",
    "    pixel_data[ix%56, ix//56] = int_colors[average_mon[ix]]\n",
    "img.save('generated_img/new_mon-{}.png'.format(timestamp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Most likely for each pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ascii text and convert to list\n",
    "filename = \"img_data/pokemon_jelly.txt\"\n",
    "images = open(filename).read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_index_of_nth_largest(array,n):\n",
    "    array_sorted = sorted(array)\n",
    "    array_sorted.reverse()\n",
    "    return array.index(array_sorted[n-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixels = [[0, 0, 0, 0] for i in range(56 * 56)]\n",
    "for image in images:\n",
    "    for pix in range(len(image)):\n",
    "        color = int(image[pix])\n",
    "        pixels[pix][color] += 1\n",
    "        \n",
    "generated_img_data = [0 for i in range(56 * 56)]\n",
    "for i in range(len(pixels)):\n",
    "    generated_img_data[i] = get_index_of_nth_largest(pixels[i],3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_colors = {3: (0,0,0), 2: (85,85,85), 1: (170,170,170), 0: (255,255,255)}\n",
    "img = Image.new('RGB', (56, 56), color = 'white')\n",
    "pixel_data = img.load()\n",
    "\n",
    "timestamp = time.time()\n",
    "for ix in range(len(generated_img_data)):\n",
    "    pixel_data[ix%56, ix//56] = int_colors[generated_img_data[ix]]\n",
    "img.save('generated_img/max, min, avg/new_mon-{}.png'.format(timestamp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. LSTM Method (Poetry Data Clone)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert images to integer data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_directory = \"img/\"\n",
    "images = []\n",
    "for file in os.listdir(image_directory):\n",
    "    if file.endswith(\".png\"):\n",
    "        full_file_name = os.path.join(image_directory, file)\n",
    "        img = Image.open(full_file_name)\n",
    "        rgb_img = img.convert('RGB')\n",
    "        images.append(rgb_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors_int = {(0,0,0): 3, (85,85,85): 2, (170,170,170): 1, (255,255,255): 0}\n",
    "f = open('img_data/pokemon_jelly.txt', 'w')\n",
    "for image in images:\n",
    "    height = image.size[0]\n",
    "    width = image.size[1]\n",
    "    image_data = []\n",
    "    for y in range(height):\n",
    "        for x in range(width):\n",
    "            r, g, b = image.getpixel((x, y))\n",
    "            color_id = colors_int[(r,g,b)]\n",
    "            image_data.append(color_id)\n",
    "    \n",
    "    f.write(''.join(str(i) for i in image_data)+'\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ascii text and convert to list\n",
    "filename = \"img_data/pokemon_jelly.txt\"\n",
    "raw_jelly = open(filename).read()\n",
    "raw_chars = list(raw_jelly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping of unique characters to integers\n",
    "chars = sorted(list(set(raw_chars)))\n",
    "char_to_int = dict((c, i) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chars: 479961\n",
      "Total vocab: 5\n"
     ]
    }
   ],
   "source": [
    "# Summarize the loaded data\n",
    "n_chars = len(raw_chars)\n",
    "n_vocab = len(chars)\n",
    "print(\"Total chars:\", n_chars)\n",
    "print(\"Total vocab:\", n_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the dataset of input to output pairs encoded as integers\n",
    "seq_length = 56//4\n",
    "dataX = []\n",
    "dataY = []\n",
    "for i in range(0, n_chars - seq_length, 1):\n",
    "    seq_in = raw_jelly[i:i + seq_length]\n",
    "    seq_out = raw_jelly[i + seq_length]\n",
    "    dataX.append([char_to_int[char] for char in seq_in])\n",
    "    dataY.append(char_to_int[seq_out])\n",
    "n_patterns = len(dataX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape X to be [samples, time steps, features]\n",
    "X = np.reshape(dataX, (n_patterns, seq_length, 1))\n",
    "\n",
    "# Normalize\n",
    "X = X / float(n_vocab)\n",
    "\n",
    "# One hot encode the output variable\n",
    "y = np_utils.to_categorical(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0802 07:10:30.190065  9332 deprecation_wrapper.py:119] From c:\\users\\henry\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0802 07:10:30.570468  9332 deprecation_wrapper.py:119] From c:\\users\\henry\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0802 07:10:30.614467  9332 deprecation_wrapper.py:119] From c:\\users\\henry\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0802 07:10:31.197435  9332 deprecation_wrapper.py:119] From c:\\users\\henry\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0802 07:10:31.216435  9332 deprecation.py:506] From c:\\users\\henry\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0802 07:10:31.258434  9332 deprecation_wrapper.py:119] From c:\\users\\henry\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0802 07:10:31.278434  9332 deprecation_wrapper.py:119] From c:\\users\\henry\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0731 23:25:32.302209  5068 deprecation.py:323] From c:\\users\\henry\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "479947/479947 [==============================] - 171s 356us/step - loss: 0.8653\n",
      "\n",
      "Epoch 00001: loss improved from inf to 0.86530, saving model to weights/weights-improvement-01-0.8653.hdf5\n",
      "Epoch 2/500\n",
      "479947/479947 [==============================] - 191s 397us/step - loss: 0.7949\n",
      "\n",
      "Epoch 00002: loss improved from 0.86530 to 0.79492, saving model to weights/weights-improvement-02-0.7949.hdf5\n",
      "Epoch 3/500\n",
      "479947/479947 [==============================] - 195s 406us/step - loss: 0.7583\n",
      "\n",
      "Epoch 00003: loss improved from 0.79492 to 0.75827, saving model to weights/weights-improvement-03-0.7583.hdf5\n",
      "Epoch 4/500\n",
      "479947/479947 [==============================] - 203s 423us/step - loss: 0.7486\n",
      "\n",
      "Epoch 00004: loss improved from 0.75827 to 0.74856, saving model to weights/weights-improvement-04-0.7486.hdf5\n",
      "Epoch 5/500\n",
      "479947/479947 [==============================] - 201s 419us/step - loss: 0.7424\n",
      "\n",
      "Epoch 00005: loss improved from 0.74856 to 0.74241, saving model to weights/weights-improvement-05-0.7424.hdf5\n",
      "Epoch 6/500\n",
      "479947/479947 [==============================] - 200s 416us/step - loss: 0.7384\n",
      "\n",
      "Epoch 00006: loss improved from 0.74241 to 0.73836, saving model to weights/weights-improvement-06-0.7384.hdf5\n",
      "Epoch 7/500\n",
      "479947/479947 [==============================] - 199s 415us/step - loss: 0.7353\n",
      "\n",
      "Epoch 00007: loss improved from 0.73836 to 0.73533, saving model to weights/weights-improvement-07-0.7353.hdf5\n",
      "Epoch 8/500\n",
      "479947/479947 [==============================] - 204s 425us/step - loss: 0.7330\n",
      "\n",
      "Epoch 00008: loss improved from 0.73533 to 0.73300, saving model to weights/weights-improvement-08-0.7330.hdf5\n",
      "Epoch 9/500\n",
      "479947/479947 [==============================] - 202s 421us/step - loss: 0.7311\n",
      "\n",
      "Epoch 00009: loss improved from 0.73300 to 0.73107, saving model to weights/weights-improvement-09-0.7311.hdf5\n",
      "Epoch 10/500\n",
      "479947/479947 [==============================] - 203s 422us/step - loss: 0.7291\n",
      "\n",
      "Epoch 00010: loss improved from 0.73107 to 0.72910, saving model to weights/weights-improvement-10-0.7291.hdf5\n",
      "Epoch 11/500\n",
      "479947/479947 [==============================] - 203s 423us/step - loss: 0.7274\n",
      "\n",
      "Epoch 00011: loss improved from 0.72910 to 0.72745, saving model to weights/weights-improvement-11-0.7274.hdf5\n",
      "Epoch 12/500\n",
      "479947/479947 [==============================] - 203s 423us/step - loss: 0.7255\n",
      "\n",
      "Epoch 00012: loss improved from 0.72745 to 0.72550, saving model to weights/weights-improvement-12-0.7255.hdf5\n",
      "Epoch 13/500\n",
      "479947/479947 [==============================] - 203s 423us/step - loss: 0.7239\n",
      "\n",
      "Epoch 00013: loss improved from 0.72550 to 0.72391, saving model to weights/weights-improvement-13-0.7239.hdf5\n",
      "Epoch 14/500\n",
      "479947/479947 [==============================] - 205s 427us/step - loss: 0.7221\n",
      "\n",
      "Epoch 00014: loss improved from 0.72391 to 0.72215, saving model to weights/weights-improvement-14-0.7221.hdf5\n",
      "Epoch 15/500\n",
      "479947/479947 [==============================] - 204s 425us/step - loss: 0.7199\n",
      "\n",
      "Epoch 00015: loss improved from 0.72215 to 0.71994, saving model to weights/weights-improvement-15-0.7199.hdf5\n",
      "Epoch 16/500\n",
      "479947/479947 [==============================] - 205s 426us/step - loss: 0.7177\n",
      "\n",
      "Epoch 00016: loss improved from 0.71994 to 0.71772, saving model to weights/weights-improvement-16-0.7177.hdf5\n",
      "Epoch 17/500\n",
      "479947/479947 [==============================] - 206s 429us/step - loss: 0.7150\n",
      "\n",
      "Epoch 00017: loss improved from 0.71772 to 0.71499, saving model to weights/weights-improvement-17-0.7150.hdf5\n",
      "Epoch 18/500\n",
      "479947/479947 [==============================] - 207s 431us/step - loss: 0.7125\n",
      "\n",
      "Epoch 00018: loss improved from 0.71499 to 0.71249, saving model to weights/weights-improvement-18-0.7125.hdf5\n",
      "Epoch 19/500\n",
      "479947/479947 [==============================] - 205s 427us/step - loss: 0.7094\n",
      "\n",
      "Epoch 00019: loss improved from 0.71249 to 0.70941, saving model to weights/weights-improvement-19-0.7094.hdf5\n",
      "Epoch 20/500\n",
      "479947/479947 [==============================] - 204s 426us/step - loss: 0.7061\n",
      "\n",
      "Epoch 00020: loss improved from 0.70941 to 0.70607, saving model to weights/weights-improvement-20-0.7061.hdf5\n",
      "Epoch 21/500\n",
      "479947/479947 [==============================] - 203s 423us/step - loss: 0.7024\n",
      "\n",
      "Epoch 00021: loss improved from 0.70607 to 0.70241, saving model to weights/weights-improvement-21-0.7024.hdf5\n",
      "Epoch 22/500\n",
      "479947/479947 [==============================] - 204s 425us/step - loss: 0.6979\n",
      "\n",
      "Epoch 00022: loss improved from 0.70241 to 0.69790, saving model to weights/weights-improvement-22-0.6979.hdf5\n",
      "Epoch 23/500\n",
      "479947/479947 [==============================] - 203s 424us/step - loss: 0.6931\n",
      "\n",
      "Epoch 00023: loss improved from 0.69790 to 0.69315, saving model to weights/weights-improvement-23-0.6931.hdf5\n",
      "Epoch 24/500\n",
      "479947/479947 [==============================] - 204s 425us/step - loss: 0.6884\n",
      "\n",
      "Epoch 00024: loss improved from 0.69315 to 0.68841, saving model to weights/weights-improvement-24-0.6884.hdf5\n",
      "Epoch 25/500\n",
      "479947/479947 [==============================] - 206s 430us/step - loss: 0.6829\n",
      "\n",
      "Epoch 00025: loss improved from 0.68841 to 0.68292, saving model to weights/weights-improvement-25-0.6829.hdf5\n",
      "Epoch 26/500\n",
      "479947/479947 [==============================] - 205s 427us/step - loss: 0.6773\n",
      "\n",
      "Epoch 00026: loss improved from 0.68292 to 0.67733, saving model to weights/weights-improvement-26-0.6773.hdf5\n",
      "Epoch 27/500\n",
      "479947/479947 [==============================] - 204s 425us/step - loss: 0.6717\n",
      "\n",
      "Epoch 00027: loss improved from 0.67733 to 0.67167, saving model to weights/weights-improvement-27-0.6717.hdf5\n",
      "Epoch 28/500\n",
      "479947/479947 [==============================] - 204s 425us/step - loss: 0.6656\n",
      "\n",
      "Epoch 00028: loss improved from 0.67167 to 0.66558, saving model to weights/weights-improvement-28-0.6656.hdf5\n",
      "Epoch 29/500\n",
      "479947/479947 [==============================] - 206s 429us/step - loss: 0.6606\n",
      "\n",
      "Epoch 00029: loss improved from 0.66558 to 0.66062, saving model to weights/weights-improvement-29-0.6606.hdf5\n",
      "Epoch 30/500\n",
      "479947/479947 [==============================] - 206s 428us/step - loss: 0.6541\n",
      "\n",
      "Epoch 00030: loss improved from 0.66062 to 0.65407, saving model to weights/weights-improvement-30-0.6541.hdf5\n",
      "Epoch 31/500\n",
      "479947/479947 [==============================] - 206s 429us/step - loss: 0.6492\n",
      "\n",
      "Epoch 00031: loss improved from 0.65407 to 0.64920, saving model to weights/weights-improvement-31-0.6492.hdf5\n",
      "Epoch 32/500\n",
      "479947/479947 [==============================] - 205s 427us/step - loss: 0.6429\n",
      "\n",
      "Epoch 00032: loss improved from 0.64920 to 0.64294, saving model to weights/weights-improvement-32-0.6429.hdf5\n",
      "Epoch 33/500\n",
      "479947/479947 [==============================] - 205s 427us/step - loss: 0.6374\n",
      "\n",
      "Epoch 00033: loss improved from 0.64294 to 0.63742, saving model to weights/weights-improvement-33-0.6374.hdf5\n",
      "Epoch 34/500\n",
      "479947/479947 [==============================] - 206s 429us/step - loss: 0.6323\n",
      "\n",
      "Epoch 00034: loss improved from 0.63742 to 0.63235, saving model to weights/weights-improvement-34-0.6323.hdf5\n",
      "Epoch 35/500\n",
      "479947/479947 [==============================] - 204s 426us/step - loss: 0.6269\n",
      "\n",
      "Epoch 00035: loss improved from 0.63235 to 0.62691, saving model to weights/weights-improvement-35-0.6269.hdf5\n",
      "Epoch 36/500\n",
      "479947/479947 [==============================] - 202s 421us/step - loss: 0.6212\n",
      "\n",
      "Epoch 00036: loss improved from 0.62691 to 0.62123, saving model to weights/weights-improvement-36-0.6212.hdf5\n",
      "Epoch 37/500\n",
      "479947/479947 [==============================] - 202s 421us/step - loss: 0.6168\n",
      "\n",
      "Epoch 00037: loss improved from 0.62123 to 0.61675, saving model to weights/weights-improvement-37-0.6168.hdf5\n",
      "Epoch 38/500\n",
      "479947/479947 [==============================] - 202s 422us/step - loss: 0.6120\n",
      "\n",
      "Epoch 00038: loss improved from 0.61675 to 0.61204, saving model to weights/weights-improvement-38-0.6120.hdf5\n",
      "Epoch 39/500\n",
      "479947/479947 [==============================] - 203s 423us/step - loss: 0.6070\n",
      "\n",
      "Epoch 00039: loss improved from 0.61204 to 0.60700, saving model to weights/weights-improvement-39-0.6070.hdf5\n",
      "Epoch 40/500\n",
      "479947/479947 [==============================] - 202s 422us/step - loss: 0.6025\n",
      "\n",
      "Epoch 00040: loss improved from 0.60700 to 0.60250, saving model to weights/weights-improvement-40-0.6025.hdf5\n",
      "Epoch 41/500\n",
      "479947/479947 [==============================] - 188s 393us/step - loss: 0.5988\n",
      "\n",
      "Epoch 00041: loss improved from 0.60250 to 0.59880, saving model to weights/weights-improvement-41-0.5988.hdf5\n",
      "Epoch 42/500\n",
      "479947/479947 [==============================] - 189s 395us/step - loss: 0.5933\n",
      "\n",
      "Epoch 00042: loss improved from 0.59880 to 0.59329, saving model to weights/weights-improvement-42-0.5933.hdf5\n",
      "Epoch 43/500\n",
      "479947/479947 [==============================] - 192s 401us/step - loss: 0.5908\n",
      "\n",
      "Epoch 00043: loss improved from 0.59329 to 0.59077, saving model to weights/weights-improvement-43-0.5908.hdf5\n",
      "Epoch 44/500\n",
      "479947/479947 [==============================] - 190s 395us/step - loss: 0.5864\n",
      "\n",
      "Epoch 00044: loss improved from 0.59077 to 0.58642, saving model to weights/weights-improvement-44-0.5864.hdf5\n",
      "Epoch 45/500\n",
      "479947/479947 [==============================] - 190s 396us/step - loss: 0.5830\n",
      "\n",
      "Epoch 00045: loss improved from 0.58642 to 0.58304, saving model to weights/weights-improvement-45-0.5830.hdf5\n",
      "Epoch 46/500\n",
      "479947/479947 [==============================] - 190s 395us/step - loss: 0.5798\n",
      "\n",
      "Epoch 00046: loss improved from 0.58304 to 0.57981, saving model to weights/weights-improvement-46-0.5798.hdf5\n",
      "Epoch 47/500\n",
      "479947/479947 [==============================] - 192s 400us/step - loss: 0.5762\n",
      "\n",
      "Epoch 00047: loss improved from 0.57981 to 0.57619, saving model to weights/weights-improvement-47-0.5762.hdf5\n",
      "Epoch 48/500\n",
      "479947/479947 [==============================] - 191s 397us/step - loss: 0.5728\n",
      "\n",
      "Epoch 00048: loss improved from 0.57619 to 0.57276, saving model to weights/weights-improvement-48-0.5728.hdf5\n",
      "Epoch 49/500\n",
      "479947/479947 [==============================] - 194s 405us/step - loss: 0.5693\n",
      "\n",
      "Epoch 00049: loss improved from 0.57276 to 0.56927, saving model to weights/weights-improvement-49-0.5693.hdf5\n",
      "Epoch 50/500\n",
      "479947/479947 [==============================] - 191s 399us/step - loss: 0.5662\n",
      "\n",
      "Epoch 00050: loss improved from 0.56927 to 0.56621, saving model to weights/weights-improvement-50-0.5662.hdf5\n",
      "Epoch 51/500\n",
      "479947/479947 [==============================] - 194s 404us/step - loss: 0.5632\n",
      "\n",
      "Epoch 00051: loss improved from 0.56621 to 0.56324, saving model to weights/weights-improvement-51-0.5632.hdf5\n",
      "Epoch 52/500\n",
      "479947/479947 [==============================] - 194s 403us/step - loss: 0.5610\n",
      "\n",
      "Epoch 00052: loss improved from 0.56324 to 0.56097, saving model to weights/weights-improvement-52-0.5610.hdf5\n",
      "Epoch 53/500\n",
      "479947/479947 [==============================] - 193s 402us/step - loss: 0.5574\n",
      "\n",
      "Epoch 00053: loss improved from 0.56097 to 0.55742, saving model to weights/weights-improvement-53-0.5574.hdf5\n",
      "Epoch 54/500\n",
      "479947/479947 [==============================] - 194s 405us/step - loss: 0.5560\n",
      "\n",
      "Epoch 00054: loss improved from 0.55742 to 0.55600, saving model to weights/weights-improvement-54-0.5560.hdf5\n",
      "Epoch 55/500\n",
      "479947/479947 [==============================] - 193s 401us/step - loss: 0.5525\n",
      "\n",
      "Epoch 00055: loss improved from 0.55600 to 0.55251, saving model to weights/weights-improvement-55-0.5525.hdf5\n",
      "Epoch 56/500\n",
      "479947/479947 [==============================] - 193s 401us/step - loss: 0.5510\n",
      "\n",
      "Epoch 00056: loss improved from 0.55251 to 0.55105, saving model to weights/weights-improvement-56-0.5510.hdf5\n",
      "Epoch 57/500\n",
      "479947/479947 [==============================] - 194s 405us/step - loss: 0.5486\n",
      "\n",
      "Epoch 00057: loss improved from 0.55105 to 0.54860, saving model to weights/weights-improvement-57-0.5486.hdf5\n",
      "Epoch 58/500\n",
      "479947/479947 [==============================] - 194s 404us/step - loss: 0.5457\n",
      "\n",
      "Epoch 00058: loss improved from 0.54860 to 0.54569, saving model to weights/weights-improvement-58-0.5457.hdf5\n",
      "Epoch 59/500\n",
      "479947/479947 [==============================] - 194s 404us/step - loss: 0.5442\n",
      "\n",
      "Epoch 00059: loss improved from 0.54569 to 0.54422, saving model to weights/weights-improvement-59-0.5442.hdf5\n",
      "Epoch 60/500\n",
      "479947/479947 [==============================] - 195s 406us/step - loss: 0.5422\n",
      "\n",
      "Epoch 00060: loss improved from 0.54422 to 0.54223, saving model to weights/weights-improvement-60-0.5422.hdf5\n",
      "Epoch 61/500\n",
      "479947/479947 [==============================] - 195s 406us/step - loss: 0.5399\n",
      "\n",
      "Epoch 00061: loss improved from 0.54223 to 0.53985, saving model to weights/weights-improvement-61-0.5399.hdf5\n",
      "Epoch 62/500\n",
      "479947/479947 [==============================] - 197s 411us/step - loss: 0.5377\n",
      "\n",
      "Epoch 00062: loss improved from 0.53985 to 0.53773, saving model to weights/weights-improvement-62-0.5377.hdf5\n",
      "Epoch 63/500\n",
      "479947/479947 [==============================] - 194s 405us/step - loss: 0.5361\n",
      "\n",
      "Epoch 00063: loss improved from 0.53773 to 0.53613, saving model to weights/weights-improvement-63-0.5361.hdf5\n",
      "Epoch 64/500\n",
      "479947/479947 [==============================] - 194s 405us/step - loss: 0.5345\n",
      "\n",
      "Epoch 00064: loss improved from 0.53613 to 0.53447, saving model to weights/weights-improvement-64-0.5345.hdf5\n",
      "Epoch 65/500\n",
      "479947/479947 [==============================] - 195s 407us/step - loss: 0.5324\n",
      "\n",
      "Epoch 00065: loss improved from 0.53447 to 0.53237, saving model to weights/weights-improvement-65-0.5324.hdf5\n",
      "Epoch 66/500\n",
      "479947/479947 [==============================] - 196s 408us/step - loss: 0.5309\n",
      "\n",
      "Epoch 00066: loss improved from 0.53237 to 0.53089, saving model to weights/weights-improvement-66-0.5309.hdf5\n",
      "Epoch 67/500\n",
      "479947/479947 [==============================] - 197s 410us/step - loss: 0.5281\n",
      "\n",
      "Epoch 00067: loss improved from 0.53089 to 0.52812, saving model to weights/weights-improvement-67-0.5281.hdf5\n",
      "Epoch 68/500\n",
      "479947/479947 [==============================] - 199s 415us/step - loss: 0.5272\n",
      "\n",
      "Epoch 00068: loss improved from 0.52812 to 0.52718, saving model to weights/weights-improvement-68-0.5272.hdf5\n",
      "Epoch 69/500\n",
      "479947/479947 [==============================] - 197s 410us/step - loss: 0.5263\n",
      "\n",
      "Epoch 00069: loss improved from 0.52718 to 0.52626, saving model to weights/weights-improvement-69-0.5263.hdf5\n",
      "Epoch 70/500\n",
      "479947/479947 [==============================] - 198s 412us/step - loss: 0.5238\n",
      "\n",
      "Epoch 00070: loss improved from 0.52626 to 0.52380, saving model to weights/weights-improvement-70-0.5238.hdf5\n",
      "Epoch 71/500\n",
      "479947/479947 [==============================] - 197s 411us/step - loss: 0.5223\n",
      "\n",
      "Epoch 00071: loss improved from 0.52380 to 0.52226, saving model to weights/weights-improvement-71-0.5223.hdf5\n",
      "Epoch 72/500\n",
      "479947/479947 [==============================] - 199s 415us/step - loss: 0.5208\n",
      "\n",
      "Epoch 00072: loss improved from 0.52226 to 0.52079, saving model to weights/weights-improvement-72-0.5208.hdf5\n",
      "Epoch 73/500\n",
      "479947/479947 [==============================] - 198s 413us/step - loss: 0.5197\n",
      "\n",
      "Epoch 00073: loss improved from 0.52079 to 0.51969, saving model to weights/weights-improvement-73-0.5197.hdf5\n",
      "Epoch 74/500\n",
      "479947/479947 [==============================] - 197s 411us/step - loss: 0.5181\n",
      "\n",
      "Epoch 00074: loss improved from 0.51969 to 0.51808, saving model to weights/weights-improvement-74-0.5181.hdf5\n",
      "Epoch 75/500\n",
      "479947/479947 [==============================] - 197s 411us/step - loss: 0.5157\n",
      "\n",
      "Epoch 00075: loss improved from 0.51808 to 0.51569, saving model to weights/weights-improvement-75-0.5157.hdf5\n",
      "Epoch 76/500\n",
      "479947/479947 [==============================] - 197s 411us/step - loss: 0.5160\n",
      "\n",
      "Epoch 00076: loss did not improve from 0.51569\n",
      "Epoch 77/500\n",
      "479947/479947 [==============================] - 197s 410us/step - loss: 0.5138\n",
      "\n",
      "Epoch 00077: loss improved from 0.51569 to 0.51383, saving model to weights/weights-improvement-77-0.5138.hdf5\n",
      "Epoch 78/500\n",
      "479947/479947 [==============================] - 197s 411us/step - loss: 0.5135\n",
      "\n",
      "Epoch 00078: loss improved from 0.51383 to 0.51346, saving model to weights/weights-improvement-78-0.5135.hdf5\n",
      "Epoch 79/500\n",
      "479947/479947 [==============================] - 198s 412us/step - loss: 0.5109\n",
      "\n",
      "Epoch 00079: loss improved from 0.51346 to 0.51094, saving model to weights/weights-improvement-79-0.5109.hdf5\n",
      "Epoch 80/500\n",
      "479947/479947 [==============================] - 199s 414us/step - loss: 0.5100\n",
      "\n",
      "Epoch 00080: loss improved from 0.51094 to 0.50999, saving model to weights/weights-improvement-80-0.5100.hdf5\n",
      "Epoch 81/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "479947/479947 [==============================] - 190s 397us/step - loss: 0.5097\n",
      "\n",
      "Epoch 00081: loss improved from 0.50999 to 0.50974, saving model to weights/weights-improvement-81-0.5097.hdf5\n",
      "Epoch 82/500\n",
      "479947/479947 [==============================] - 189s 394us/step - loss: 0.5073\n",
      "\n",
      "Epoch 00082: loss improved from 0.50974 to 0.50734, saving model to weights/weights-improvement-82-0.5073.hdf5\n",
      "Epoch 83/500\n",
      "479947/479947 [==============================] - 192s 399us/step - loss: 0.5068\n",
      "\n",
      "Epoch 00083: loss improved from 0.50734 to 0.50679, saving model to weights/weights-improvement-83-0.5068.hdf5\n",
      "Epoch 84/500\n",
      "479947/479947 [==============================] - 192s 399us/step - loss: 0.5058\n",
      "\n",
      "Epoch 00084: loss improved from 0.50679 to 0.50575, saving model to weights/weights-improvement-84-0.5058.hdf5\n",
      "Epoch 85/500\n",
      "479947/479947 [==============================] - 191s 398us/step - loss: 0.5036\n",
      "\n",
      "Epoch 00085: loss improved from 0.50575 to 0.50359, saving model to weights/weights-improvement-85-0.5036.hdf5\n",
      "Epoch 86/500\n",
      "479947/479947 [==============================] - 193s 401us/step - loss: 0.5039\n",
      "\n",
      "Epoch 00086: loss did not improve from 0.50359\n",
      "Epoch 87/500\n",
      "479947/479947 [==============================] - 192s 400us/step - loss: 0.5014\n",
      "\n",
      "Epoch 00087: loss improved from 0.50359 to 0.50144, saving model to weights/weights-improvement-87-0.5014.hdf5\n",
      "Epoch 88/500\n",
      "479947/479947 [==============================] - 192s 400us/step - loss: 0.5014\n",
      "\n",
      "Epoch 00088: loss improved from 0.50144 to 0.50136, saving model to weights/weights-improvement-88-0.5014.hdf5\n",
      "Epoch 89/500\n",
      "479947/479947 [==============================] - 193s 401us/step - loss: 0.4998\n",
      "\n",
      "Epoch 00089: loss improved from 0.50136 to 0.49979, saving model to weights/weights-improvement-89-0.4998.hdf5\n",
      "Epoch 90/500\n",
      "479947/479947 [==============================] - 192s 400us/step - loss: 0.4996\n",
      "\n",
      "Epoch 00090: loss improved from 0.49979 to 0.49960, saving model to weights/weights-improvement-90-0.4996.hdf5\n",
      "Epoch 91/500\n",
      "479947/479947 [==============================] - 194s 403us/step - loss: 0.4970\n",
      "\n",
      "Epoch 00091: loss improved from 0.49960 to 0.49704, saving model to weights/weights-improvement-91-0.4970.hdf5\n",
      "Epoch 92/500\n",
      "479947/479947 [==============================] - 191s 398us/step - loss: 0.4967\n",
      "\n",
      "Epoch 00092: loss improved from 0.49704 to 0.49672, saving model to weights/weights-improvement-92-0.4967.hdf5\n",
      "Epoch 93/500\n",
      "479947/479947 [==============================] - 191s 398us/step - loss: 0.4955\n",
      "\n",
      "Epoch 00093: loss improved from 0.49672 to 0.49554, saving model to weights/weights-improvement-93-0.4955.hdf5\n",
      "Epoch 94/500\n",
      "479947/479947 [==============================] - 193s 401us/step - loss: 0.4956\n",
      "\n",
      "Epoch 00094: loss did not improve from 0.49554\n",
      "Epoch 95/500\n",
      "479947/479947 [==============================] - 198s 413us/step - loss: 0.4937\n",
      "\n",
      "Epoch 00095: loss improved from 0.49554 to 0.49366, saving model to weights/weights-improvement-95-0.4937.hdf5\n",
      "Epoch 96/500\n",
      "479947/479947 [==============================] - 198s 413us/step - loss: 0.4931\n",
      "\n",
      "Epoch 00096: loss improved from 0.49366 to 0.49314, saving model to weights/weights-improvement-96-0.4931.hdf5\n",
      "Epoch 97/500\n",
      "479947/479947 [==============================] - 197s 411us/step - loss: 0.4927s\n",
      "\n",
      "Epoch 00097: loss improved from 0.49314 to 0.49272, saving model to weights/weights-improvement-97-0.4927.hdf5\n",
      "Epoch 98/500\n",
      "479947/479947 [==============================] - 199s 414us/step - loss: 0.4919\n",
      "\n",
      "Epoch 00098: loss improved from 0.49272 to 0.49191, saving model to weights/weights-improvement-98-0.4919.hdf5\n",
      "Epoch 99/500\n",
      "479947/479947 [==============================] - 206s 430us/step - loss: 0.4910\n",
      "\n",
      "Epoch 00099: loss improved from 0.49191 to 0.49104, saving model to weights/weights-improvement-99-0.4910.hdf5\n",
      "Epoch 100/500\n",
      "479947/479947 [==============================] - 197s 410us/step - loss: 0.4909\n",
      "\n",
      "Epoch 00100: loss improved from 0.49104 to 0.49086, saving model to weights/weights-improvement-100-0.4909.hdf5\n",
      "Epoch 101/500\n",
      "479947/479947 [==============================] - 193s 401us/step - loss: 0.4885\n",
      "\n",
      "Epoch 00101: loss improved from 0.49086 to 0.48853, saving model to weights/weights-improvement-101-0.4885.hdf5\n",
      "Epoch 102/500\n",
      "479947/479947 [==============================] - 194s 404us/step - loss: 0.4879\n",
      "\n",
      "Epoch 00102: loss improved from 0.48853 to 0.48786, saving model to weights/weights-improvement-102-0.4879.hdf5\n",
      "Epoch 103/500\n",
      "479947/479947 [==============================] - 193s 402us/step - loss: 0.4877\n",
      "\n",
      "Epoch 00103: loss improved from 0.48786 to 0.48768, saving model to weights/weights-improvement-103-0.4877.hdf5\n",
      "Epoch 104/500\n",
      "479947/479947 [==============================] - 197s 410us/step - loss: 0.4872\n",
      "\n",
      "Epoch 00104: loss improved from 0.48768 to 0.48720, saving model to weights/weights-improvement-104-0.4872.hdf5\n",
      "Epoch 105/500\n",
      "479947/479947 [==============================] - 194s 404us/step - loss: 0.4857\n",
      "\n",
      "Epoch 00105: loss improved from 0.48720 to 0.48567, saving model to weights/weights-improvement-105-0.4857.hdf5\n",
      "Epoch 106/500\n",
      "479947/479947 [==============================] - 194s 404us/step - loss: 0.4852\n",
      "\n",
      "Epoch 00106: loss improved from 0.48567 to 0.48515, saving model to weights/weights-improvement-106-0.4852.hdf5\n",
      "Epoch 107/500\n",
      "479947/479947 [==============================] - 194s 405us/step - loss: 0.4849\n",
      "\n",
      "Epoch 00107: loss improved from 0.48515 to 0.48489, saving model to weights/weights-improvement-107-0.4849.hdf5\n",
      "Epoch 108/500\n",
      "479947/479947 [==============================] - 196s 409us/step - loss: 0.4837\n",
      "\n",
      "Epoch 00108: loss improved from 0.48489 to 0.48368, saving model to weights/weights-improvement-108-0.4837.hdf5\n",
      "Epoch 109/500\n",
      "479947/479947 [==============================] - 195s 407us/step - loss: 0.4832\n",
      "\n",
      "Epoch 00109: loss improved from 0.48368 to 0.48322, saving model to weights/weights-improvement-109-0.4832.hdf5\n",
      "Epoch 110/500\n",
      "479947/479947 [==============================] - 195s 407us/step - loss: 0.4823\n",
      "\n",
      "Epoch 00110: loss improved from 0.48322 to 0.48231, saving model to weights/weights-improvement-110-0.4823.hdf5\n",
      "Epoch 111/500\n",
      "479947/479947 [==============================] - 196s 409us/step - loss: 0.4817\n",
      "\n",
      "Epoch 00111: loss improved from 0.48231 to 0.48174, saving model to weights/weights-improvement-111-0.4817.hdf5\n",
      "Epoch 112/500\n",
      "479947/479947 [==============================] - 198s 412us/step - loss: 0.4805\n",
      "\n",
      "Epoch 00112: loss improved from 0.48174 to 0.48055, saving model to weights/weights-improvement-112-0.4805.hdf5\n",
      "Epoch 113/500\n",
      "479947/479947 [==============================] - 197s 411us/step - loss: 0.4806\n",
      "\n",
      "Epoch 00113: loss did not improve from 0.48055\n",
      "Epoch 114/500\n",
      "479947/479947 [==============================] - 199s 414us/step - loss: 0.4800\n",
      "\n",
      "Epoch 00114: loss improved from 0.48055 to 0.47997, saving model to weights/weights-improvement-114-0.4800.hdf5\n",
      "Epoch 115/500\n",
      "479947/479947 [==============================] - 197s 411us/step - loss: 0.4797\n",
      "\n",
      "Epoch 00115: loss improved from 0.47997 to 0.47965, saving model to weights/weights-improvement-115-0.4797.hdf5\n",
      "Epoch 116/500\n",
      "479947/479947 [==============================] - 197s 410us/step - loss: 0.4778\n",
      "\n",
      "Epoch 00116: loss improved from 0.47965 to 0.47785, saving model to weights/weights-improvement-116-0.4778.hdf5\n",
      "Epoch 117/500\n",
      "479947/479947 [==============================] - 200s 417us/step - loss: 0.4774\n",
      "\n",
      "Epoch 00117: loss improved from 0.47785 to 0.47745, saving model to weights/weights-improvement-117-0.4774.hdf5\n",
      "Epoch 118/500\n",
      "479947/479947 [==============================] - 197s 410us/step - loss: 0.4766\n",
      "\n",
      "Epoch 00118: loss improved from 0.47745 to 0.47657, saving model to weights/weights-improvement-118-0.4766.hdf5\n",
      "Epoch 119/500\n",
      "479947/479947 [==============================] - 195s 407us/step - loss: 0.4766\n",
      "\n",
      "Epoch 00119: loss did not improve from 0.47657\n",
      "Epoch 120/500\n",
      "479947/479947 [==============================] - 195s 407us/step - loss: 0.4744\n",
      "\n",
      "Epoch 00120: loss improved from 0.47657 to 0.47441, saving model to weights/weights-improvement-120-0.4744.hdf5\n",
      "Epoch 121/500\n",
      "479947/479947 [==============================] - 197s 411us/step - loss: 0.4755\n",
      "\n",
      "Epoch 00121: loss did not improve from 0.47441\n",
      "Epoch 122/500\n",
      "479947/479947 [==============================] - 190s 397us/step - loss: 0.4734\n",
      "\n",
      "Epoch 00122: loss improved from 0.47441 to 0.47343, saving model to weights/weights-improvement-122-0.4734.hdf5\n",
      "Epoch 123/500\n",
      "479947/479947 [==============================] - 192s 400us/step - loss: 0.4743\n",
      "\n",
      "Epoch 00123: loss did not improve from 0.47343\n",
      "Epoch 124/500\n",
      "479947/479947 [==============================] - 191s 399us/step - loss: 0.4743\n",
      "\n",
      "Epoch 00124: loss did not improve from 0.47343\n",
      "Epoch 125/500\n",
      "479947/479947 [==============================] - 193s 402us/step - loss: 0.4729\n",
      "\n",
      "Epoch 00125: loss improved from 0.47343 to 0.47294, saving model to weights/weights-improvement-125-0.4729.hdf5\n",
      "Epoch 126/500\n",
      "479947/479947 [==============================] - 192s 400us/step - loss: 0.4717\n",
      "\n",
      "Epoch 00126: loss improved from 0.47294 to 0.47167, saving model to weights/weights-improvement-126-0.4717.hdf5\n",
      "Epoch 127/500\n",
      "479947/479947 [==============================] - 192s 400us/step - loss: 0.4716\n",
      "\n",
      "Epoch 00127: loss improved from 0.47167 to 0.47155, saving model to weights/weights-improvement-127-0.4716.hdf5\n",
      "Epoch 128/500\n",
      "479947/479947 [==============================] - 192s 400us/step - loss: 0.4713\n",
      "\n",
      "Epoch 00128: loss improved from 0.47155 to 0.47132, saving model to weights/weights-improvement-128-0.4713.hdf5\n",
      "Epoch 129/500\n",
      "479947/479947 [==============================] - 191s 399us/step - loss: 0.4707\n",
      "\n",
      "Epoch 00129: loss improved from 0.47132 to 0.47075, saving model to weights/weights-improvement-129-0.4707.hdf5\n",
      "Epoch 130/500\n",
      "479947/479947 [==============================] - 192s 400us/step - loss: 0.4705\n",
      "\n",
      "Epoch 00130: loss improved from 0.47075 to 0.47048, saving model to weights/weights-improvement-130-0.4705.hdf5\n",
      "Epoch 131/500\n",
      "479947/479947 [==============================] - 195s 406us/step - loss: 0.4688\n",
      "\n",
      "Epoch 00131: loss improved from 0.47048 to 0.46882, saving model to weights/weights-improvement-131-0.4688.hdf5\n",
      "Epoch 132/500\n",
      "479947/479947 [==============================] - 193s 402us/step - loss: 0.4695\n",
      "\n",
      "Epoch 00132: loss did not improve from 0.46882\n",
      "Epoch 133/500\n",
      "479947/479947 [==============================] - 193s 402us/step - loss: 0.4681\n",
      "\n",
      "Epoch 00133: loss improved from 0.46882 to 0.46807, saving model to weights/weights-improvement-133-0.4681.hdf5\n",
      "Epoch 134/500\n",
      "479947/479947 [==============================] - 192s 400us/step - loss: 0.4675\n",
      "\n",
      "Epoch 00134: loss improved from 0.46807 to 0.46750, saving model to weights/weights-improvement-134-0.4675.hdf5\n",
      "Epoch 135/500\n",
      "479947/479947 [==============================] - 196s 408us/step - loss: 0.4674\n",
      "\n",
      "Epoch 00135: loss improved from 0.46750 to 0.46737, saving model to weights/weights-improvement-135-0.4674.hdf5\n",
      "Epoch 136/500\n",
      "479947/479947 [==============================] - 202s 421us/step - loss: 0.4660\n",
      "\n",
      "Epoch 00136: loss improved from 0.46737 to 0.46596, saving model to weights/weights-improvement-136-0.4660.hdf5\n",
      "Epoch 137/500\n",
      "479947/479947 [==============================] - 193s 403us/step - loss: 0.4666\n",
      "\n",
      "Epoch 00137: loss did not improve from 0.46596\n",
      "Epoch 138/500\n",
      "479947/479947 [==============================] - 193s 401us/step - loss: 0.4655\n",
      "\n",
      "Epoch 00138: loss improved from 0.46596 to 0.46551, saving model to weights/weights-improvement-138-0.4655.hdf5\n",
      "Epoch 139/500\n",
      "479947/479947 [==============================] - 193s 403us/step - loss: 0.4648\n",
      "\n",
      "Epoch 00139: loss improved from 0.46551 to 0.46484, saving model to weights/weights-improvement-139-0.4648.hdf5\n",
      "Epoch 140/500\n",
      "479947/479947 [==============================] - 200s 416us/step - loss: 0.4644\n",
      "\n",
      "Epoch 00140: loss improved from 0.46484 to 0.46436, saving model to weights/weights-improvement-140-0.4644.hdf5\n",
      "Epoch 141/500\n",
      "479947/479947 [==============================] - 206s 430us/step - loss: 0.4646\n",
      "\n",
      "Epoch 00141: loss did not improve from 0.46436\n",
      "Epoch 142/500\n",
      "479947/479947 [==============================] - 206s 428us/step - loss: 0.4626\n",
      "\n",
      "Epoch 00142: loss improved from 0.46436 to 0.46261, saving model to weights/weights-improvement-142-0.4626.hdf5\n",
      "Epoch 143/500\n",
      "479947/479947 [==============================] - 206s 429us/step - loss: 0.4631\n",
      "\n",
      "Epoch 00143: loss did not improve from 0.46261\n",
      "Epoch 144/500\n",
      "479947/479947 [==============================] - 211s 439us/step - loss: 0.4631s - loss\n",
      "\n",
      "Epoch 00144: loss did not improve from 0.46261\n",
      "Epoch 145/500\n",
      "479947/479947 [==============================] - 225s 470us/step - loss: 0.4626\n",
      "\n",
      "Epoch 00145: loss did not improve from 0.46261\n",
      "Epoch 146/500\n",
      "479947/479947 [==============================] - 219s 457us/step - loss: 0.4621\n",
      "\n",
      "Epoch 00146: loss improved from 0.46261 to 0.46208, saving model to weights/weights-improvement-146-0.4621.hdf5\n",
      "Epoch 147/500\n",
      "479947/479947 [==============================] - 223s 465us/step - loss: 0.4609\n",
      "\n",
      "Epoch 00147: loss improved from 0.46208 to 0.46094, saving model to weights/weights-improvement-147-0.4609.hdf5\n",
      "Epoch 148/500\n",
      "479947/479947 [==============================] - 211s 440us/step - loss: 0.4618\n",
      "\n",
      "Epoch 00148: loss did not improve from 0.46094\n",
      "Epoch 149/500\n",
      "479947/479947 [==============================] - 197s 410us/step - loss: 0.4604s - lo\n",
      "\n",
      "Epoch 00149: loss improved from 0.46094 to 0.46045, saving model to weights/weights-improvement-149-0.4604.hdf5\n",
      "Epoch 150/500\n",
      "479947/479947 [==============================] - 214s 446us/step - loss: 0.4597\n",
      "\n",
      "Epoch 00150: loss improved from 0.46045 to 0.45965, saving model to weights/weights-improvement-150-0.4597.hdf5\n",
      "Epoch 151/500\n",
      "479947/479947 [==============================] - 206s 429us/step - loss: 0.4598\n",
      "\n",
      "Epoch 00151: loss did not improve from 0.45965\n",
      "Epoch 152/500\n",
      "479947/479947 [==============================] - 206s 430us/step - loss: 0.4593\n",
      "\n",
      "Epoch 00152: loss improved from 0.45965 to 0.45931, saving model to weights/weights-improvement-152-0.4593.hdf5\n",
      "Epoch 153/500\n",
      "479947/479947 [==============================] - 212s 442us/step - loss: 0.4592\n",
      "\n",
      "Epoch 00153: loss improved from 0.45931 to 0.45917, saving model to weights/weights-improvement-153-0.4592.hdf5\n",
      "Epoch 154/500\n",
      "479947/479947 [==============================] - 207s 432us/step - loss: 0.4589\n",
      "\n",
      "Epoch 00154: loss improved from 0.45917 to 0.45895, saving model to weights/weights-improvement-154-0.4589.hdf5\n",
      "Epoch 155/500\n",
      "479947/479947 [==============================] - 215s 448us/step - loss: 0.4581\n",
      "\n",
      "Epoch 00155: loss improved from 0.45895 to 0.45810, saving model to weights/weights-improvement-155-0.4581.hdf5\n",
      "Epoch 156/500\n",
      "479947/479947 [==============================] - 205s 427us/step - loss: 0.4576\n",
      "\n",
      "Epoch 00156: loss improved from 0.45810 to 0.45758, saving model to weights/weights-improvement-156-0.4576.hdf5\n",
      "Epoch 157/500\n",
      "479947/479947 [==============================] - 205s 427us/step - loss: 0.4571\n",
      "\n",
      "Epoch 00157: loss improved from 0.45758 to 0.45707, saving model to weights/weights-improvement-157-0.4571.hdf5\n",
      "Epoch 158/500\n",
      "479947/479947 [==============================] - 204s 426us/step - loss: 0.4568\n",
      "\n",
      "Epoch 00158: loss improved from 0.45707 to 0.45678, saving model to weights/weights-improvement-158-0.4568.hdf5\n",
      "Epoch 159/500\n",
      "479947/479947 [==============================] - 202s 420us/step - loss: 0.4564\n",
      "\n",
      "Epoch 00159: loss improved from 0.45678 to 0.45641, saving model to weights/weights-improvement-159-0.4564.hdf5\n",
      "Epoch 160/500\n",
      "479947/479947 [==============================] - 203s 423us/step - loss: 0.4553\n",
      "\n",
      "Epoch 00160: loss improved from 0.45641 to 0.45532, saving model to weights/weights-improvement-160-0.4553.hdf5\n",
      "Epoch 161/500\n",
      "479947/479947 [==============================] - 201s 419us/step - loss: 0.4562\n",
      "\n",
      "Epoch 00161: loss did not improve from 0.45532\n",
      "Epoch 162/500\n",
      "479947/479947 [==============================] - 202s 422us/step - loss: 0.4556\n",
      "\n",
      "Epoch 00162: loss did not improve from 0.45532\n",
      "Epoch 163/500\n",
      "479947/479947 [==============================] - 203s 423us/step - loss: 0.4549\n",
      "\n",
      "Epoch 00163: loss improved from 0.45532 to 0.45491, saving model to weights/weights-improvement-163-0.4549.hdf5\n",
      "Epoch 164/500\n",
      "479947/479947 [==============================] - 201s 420us/step - loss: 0.4540\n",
      "\n",
      "Epoch 00164: loss improved from 0.45491 to 0.45400, saving model to weights/weights-improvement-164-0.4540.hdf5\n",
      "Epoch 165/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "479947/479947 [==============================] - 189s 395us/step - loss: 0.4537\n",
      "\n",
      "Epoch 00165: loss improved from 0.45400 to 0.45371, saving model to weights/weights-improvement-165-0.4537.hdf5\n",
      "Epoch 166/500\n",
      "479947/479947 [==============================] - 188s 392us/step - loss: 0.4536\n",
      "\n",
      "Epoch 00166: loss improved from 0.45371 to 0.45359, saving model to weights/weights-improvement-166-0.4536.hdf5\n",
      "Epoch 167/500\n",
      "479947/479947 [==============================] - 189s 394us/step - loss: 0.4539\n",
      "\n",
      "Epoch 00167: loss did not improve from 0.45359\n",
      "Epoch 168/500\n",
      "479947/479947 [==============================] - 189s 395us/step - loss: 0.4520\n",
      "\n",
      "Epoch 00168: loss improved from 0.45359 to 0.45203, saving model to weights/weights-improvement-168-0.4520.hdf5\n",
      "Epoch 169/500\n",
      "479947/479947 [==============================] - 189s 394us/step - loss: 0.4521\n",
      "\n",
      "Epoch 00169: loss did not improve from 0.45203\n",
      "Epoch 170/500\n",
      "479947/479947 [==============================] - 189s 393us/step - loss: 0.4521\n",
      "\n",
      "Epoch 00170: loss did not improve from 0.45203\n",
      "Epoch 171/500\n",
      "479947/479947 [==============================] - 194s 404us/step - loss: 0.4513\n",
      "\n",
      "Epoch 00171: loss improved from 0.45203 to 0.45127, saving model to weights/weights-improvement-171-0.4513.hdf5\n",
      "Epoch 172/500\n",
      "479947/479947 [==============================] - 191s 397us/step - loss: 0.4518\n",
      "\n",
      "Epoch 00172: loss did not improve from 0.45127\n",
      "Epoch 173/500\n",
      "479947/479947 [==============================] - 190s 397us/step - loss: 0.4512\n",
      "\n",
      "Epoch 00173: loss improved from 0.45127 to 0.45119, saving model to weights/weights-improvement-173-0.4512.hdf5\n",
      "Epoch 174/500\n",
      "479947/479947 [==============================] - 190s 396us/step - loss: 0.4510\n",
      "\n",
      "Epoch 00174: loss improved from 0.45119 to 0.45096, saving model to weights/weights-improvement-174-0.4510.hdf5\n",
      "Epoch 175/500\n",
      "479947/479947 [==============================] - 190s 396us/step - loss: 0.4504\n",
      "\n",
      "Epoch 00175: loss improved from 0.45096 to 0.45038, saving model to weights/weights-improvement-175-0.4504.hdf5\n",
      "Epoch 176/500\n",
      "479947/479947 [==============================] - 191s 397us/step - loss: 0.4502\n",
      "\n",
      "Epoch 00176: loss improved from 0.45038 to 0.45021, saving model to weights/weights-improvement-176-0.4502.hdf5\n",
      "Epoch 177/500\n",
      "479947/479947 [==============================] - 190s 396us/step - loss: 0.4488\n",
      "\n",
      "Epoch 00177: loss improved from 0.45021 to 0.44879, saving model to weights/weights-improvement-177-0.4488.hdf5\n",
      "Epoch 178/500\n",
      "479947/479947 [==============================] - 190s 396us/step - loss: 0.4497\n",
      "\n",
      "Epoch 00178: loss did not improve from 0.44879\n",
      "Epoch 179/500\n",
      "479947/479947 [==============================] - 191s 398us/step - loss: 0.4492\n",
      "\n",
      "Epoch 00179: loss did not improve from 0.44879\n",
      "Epoch 180/500\n",
      "479947/479947 [==============================] - 190s 397us/step - loss: 0.4492\n",
      "\n",
      "Epoch 00180: loss did not improve from 0.44879\n",
      "Epoch 181/500\n",
      "479947/479947 [==============================] - 196s 408us/step - loss: 0.4484\n",
      "\n",
      "Epoch 00181: loss improved from 0.44879 to 0.44842, saving model to weights/weights-improvement-181-0.4484.hdf5\n",
      "Epoch 182/500\n",
      "479947/479947 [==============================] - 191s 398us/step - loss: 0.4483\n",
      "\n",
      "Epoch 00182: loss improved from 0.44842 to 0.44833, saving model to weights/weights-improvement-182-0.4483.hdf5\n",
      "Epoch 183/500\n",
      "479947/479947 [==============================] - 192s 400us/step - loss: 0.4482\n",
      "\n",
      "Epoch 00183: loss improved from 0.44833 to 0.44819, saving model to weights/weights-improvement-183-0.4482.hdf5\n",
      "Epoch 184/500\n",
      "479947/479947 [==============================] - 193s 401us/step - loss: 0.4475\n",
      "\n",
      "Epoch 00184: loss improved from 0.44819 to 0.44754, saving model to weights/weights-improvement-184-0.4475.hdf5\n",
      "Epoch 185/500\n",
      "479947/479947 [==============================] - 192s 401us/step - loss: 0.4461\n",
      "\n",
      "Epoch 00185: loss improved from 0.44754 to 0.44611, saving model to weights/weights-improvement-185-0.4461.hdf5\n",
      "Epoch 186/500\n",
      "479947/479947 [==============================] - 193s 403us/step - loss: 0.4469\n",
      "\n",
      "Epoch 00186: loss did not improve from 0.44611\n",
      "Epoch 187/500\n",
      "479947/479947 [==============================] - 194s 404us/step - loss: 0.4458\n",
      "\n",
      "Epoch 00187: loss improved from 0.44611 to 0.44584, saving model to weights/weights-improvement-187-0.4458.hdf5\n",
      "Epoch 188/500\n",
      "479947/479947 [==============================] - 198s 413us/step - loss: 0.4462\n",
      "\n",
      "Epoch 00188: loss did not improve from 0.44584\n",
      "Epoch 189/500\n",
      "479947/479947 [==============================] - 195s 407us/step - loss: 0.4461\n",
      "\n",
      "Epoch 00189: loss did not improve from 0.44584\n",
      "Epoch 190/500\n",
      "479947/479947 [==============================] - 196s 409us/step - loss: 0.4459\n",
      "\n",
      "Epoch 00190: loss did not improve from 0.44584\n",
      "Epoch 191/500\n",
      "479947/479947 [==============================] - 194s 404us/step - loss: 0.4452\n",
      "\n",
      "Epoch 00191: loss improved from 0.44584 to 0.44516, saving model to weights/weights-improvement-191-0.4452.hdf5\n",
      "Epoch 192/500\n",
      "479947/479947 [==============================] - 194s 403us/step - loss: 0.4449\n",
      "\n",
      "Epoch 00192: loss improved from 0.44516 to 0.44490, saving model to weights/weights-improvement-192-0.4449.hdf5\n",
      "Epoch 193/500\n",
      "479947/479947 [==============================] - 196s 408us/step - loss: 0.4447\n",
      "\n",
      "Epoch 00193: loss improved from 0.44490 to 0.44473, saving model to weights/weights-improvement-193-0.4447.hdf5\n",
      "Epoch 194/500\n",
      "479947/479947 [==============================] - 196s 407us/step - loss: 0.4442\n",
      "\n",
      "Epoch 00194: loss improved from 0.44473 to 0.44424, saving model to weights/weights-improvement-194-0.4442.hdf5\n",
      "Epoch 195/500\n",
      "479947/479947 [==============================] - 194s 405us/step - loss: 0.4441\n",
      "\n",
      "Epoch 00195: loss improved from 0.44424 to 0.44410, saving model to weights/weights-improvement-195-0.4441.hdf5\n",
      "Epoch 196/500\n",
      "479947/479947 [==============================] - 196s 408us/step - loss: 0.4432\n",
      "\n",
      "Epoch 00196: loss improved from 0.44410 to 0.44323, saving model to weights/weights-improvement-196-0.4432.hdf5\n",
      "Epoch 197/500\n",
      "479947/479947 [==============================] - 196s 408us/step - loss: 0.4431\n",
      "\n",
      "Epoch 00197: loss improved from 0.44323 to 0.44311, saving model to weights/weights-improvement-197-0.4431.hdf5\n",
      "Epoch 198/500\n",
      "479947/479947 [==============================] - 198s 414us/step - loss: 0.4433\n",
      "\n",
      "Epoch 00198: loss did not improve from 0.44311\n",
      "Epoch 199/500\n",
      "479947/479947 [==============================] - 196s 408us/step - loss: 0.4433\n",
      "\n",
      "Epoch 00199: loss did not improve from 0.44311\n",
      "Epoch 200/500\n",
      "479947/479947 [==============================] - 197s 410us/step - loss: 0.4419\n",
      "\n",
      "Epoch 00200: loss improved from 0.44311 to 0.44191, saving model to weights/weights-improvement-200-0.4419.hdf5\n",
      "Epoch 201/500\n",
      "479947/479947 [==============================] - 195s 406us/step - loss: 0.4432\n",
      "\n",
      "Epoch 00201: loss did not improve from 0.44191\n",
      "Epoch 202/500\n",
      "479947/479947 [==============================] - 194s 405us/step - loss: 0.4417\n",
      "\n",
      "Epoch 00202: loss improved from 0.44191 to 0.44169, saving model to weights/weights-improvement-202-0.4417.hdf5\n",
      "Epoch 203/500\n",
      "479947/479947 [==============================] - 196s 408us/step - loss: 0.4403\n",
      "\n",
      "Epoch 00203: loss improved from 0.44169 to 0.44026, saving model to weights/weights-improvement-203-0.4403.hdf5\n",
      "Epoch 204/500\n",
      "479947/479947 [==============================] - 196s 409us/step - loss: 0.4421\n",
      "\n",
      "Epoch 00204: loss did not improve from 0.44026\n",
      "Epoch 205/500\n",
      "479947/479947 [==============================] - 196s 409us/step - loss: 0.4410\n",
      "\n",
      "Epoch 00205: loss did not improve from 0.44026\n",
      "Epoch 206/500\n",
      "479947/479947 [==============================] - 197s 410us/step - loss: 0.4406\n",
      "\n",
      "Epoch 00206: loss did not improve from 0.44026\n",
      "Epoch 207/500\n",
      "479947/479947 [==============================] - 197s 411us/step - loss: 0.4411\n",
      "\n",
      "Epoch 00207: loss did not improve from 0.44026\n",
      "Epoch 208/500\n",
      "479947/479947 [==============================] - 200s 416us/step - loss: 0.4409\n",
      "\n",
      "Epoch 00208: loss did not improve from 0.44026\n",
      "Epoch 209/500\n",
      "479947/479947 [==============================] - 200s 417us/step - loss: 0.4413\n",
      "\n",
      "Epoch 00209: loss did not improve from 0.44026\n",
      "Epoch 210/500\n",
      "479947/479947 [==============================] - 197s 411us/step - loss: 0.4396\n",
      "\n",
      "Epoch 00210: loss improved from 0.44026 to 0.43962, saving model to weights/weights-improvement-210-0.4396.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 211/500\n",
      "479947/479947 [==============================] - 188s 391us/step - loss: 0.4397\n",
      "\n",
      "Epoch 00211: loss did not improve from 0.43962\n",
      "Epoch 212/500\n",
      "479947/479947 [==============================] - 189s 393us/step - loss: 0.4401\n",
      "\n",
      "Epoch 00212: loss did not improve from 0.43962\n",
      "Epoch 213/500\n",
      "479947/479947 [==============================] - 189s 394us/step - loss: 0.4391\n",
      "\n",
      "Epoch 00213: loss improved from 0.43962 to 0.43907, saving model to weights/weights-improvement-213-0.4391.hdf5\n",
      "Epoch 214/500\n",
      "479947/479947 [==============================] - 191s 397us/step - loss: 0.4384\n",
      "\n",
      "Epoch 00214: loss improved from 0.43907 to 0.43841, saving model to weights/weights-improvement-214-0.4384.hdf5\n",
      "Epoch 215/500\n",
      "479947/479947 [==============================] - 188s 392us/step - loss: 0.4382\n",
      "\n",
      "Epoch 00215: loss improved from 0.43841 to 0.43824, saving model to weights/weights-improvement-215-0.4382.hdf5\n",
      "Epoch 216/500\n",
      "479947/479947 [==============================] - 190s 396us/step - loss: 0.4381\n",
      "\n",
      "Epoch 00216: loss improved from 0.43824 to 0.43809, saving model to weights/weights-improvement-216-0.4381.hdf5\n",
      "Epoch 217/500\n",
      "479947/479947 [==============================] - 189s 394us/step - loss: 0.4381\n",
      "\n",
      "Epoch 00217: loss did not improve from 0.43809\n",
      "Epoch 218/500\n",
      "479947/479947 [==============================] - 191s 397us/step - loss: 0.4377\n",
      "\n",
      "Epoch 00218: loss improved from 0.43809 to 0.43768, saving model to weights/weights-improvement-218-0.4377.hdf5\n",
      "Epoch 219/500\n",
      "479947/479947 [==============================] - 191s 397us/step - loss: 0.4378\n",
      "\n",
      "Epoch 00219: loss did not improve from 0.43768\n",
      "Epoch 220/500\n",
      "479947/479947 [==============================] - 189s 394us/step - loss: 0.4368\n",
      "\n",
      "Epoch 00220: loss improved from 0.43768 to 0.43682, saving model to weights/weights-improvement-220-0.4368.hdf5\n",
      "Epoch 221/500\n",
      "479947/479947 [==============================] - 190s 397us/step - loss: 0.4371\n",
      "\n",
      "Epoch 00221: loss did not improve from 0.43682\n",
      "Epoch 222/500\n",
      "479947/479947 [==============================] - 190s 395us/step - loss: 0.4373\n",
      "\n",
      "Epoch 00222: loss did not improve from 0.43682\n",
      "Epoch 223/500\n",
      "479947/479947 [==============================] - 192s 399us/step - loss: 0.4371\n",
      "\n",
      "Epoch 00223: loss did not improve from 0.43682\n",
      "Epoch 224/500\n",
      "479947/479947 [==============================] - 190s 396us/step - loss: 0.4361\n",
      "\n",
      "Epoch 00224: loss improved from 0.43682 to 0.43612, saving model to weights/weights-improvement-224-0.4361.hdf5\n",
      "Epoch 225/500\n",
      "479947/479947 [==============================] - 192s 399us/step - loss: 0.4365\n",
      "\n",
      "Epoch 00225: loss did not improve from 0.43612\n",
      "Epoch 226/500\n",
      "479947/479947 [==============================] - 194s 404us/step - loss: 0.4362\n",
      "\n",
      "Epoch 00226: loss did not improve from 0.43612\n",
      "Epoch 227/500\n",
      "479947/479947 [==============================] - 194s 404us/step - loss: 0.4353\n",
      "\n",
      "Epoch 00227: loss improved from 0.43612 to 0.43533, saving model to weights/weights-improvement-227-0.4353.hdf5\n",
      "Epoch 228/500\n",
      "479947/479947 [==============================] - 193s 402us/step - loss: 0.4358\n",
      "\n",
      "Epoch 00228: loss did not improve from 0.43533\n",
      "Epoch 229/500\n",
      "479947/479947 [==============================] - 191s 399us/step - loss: 0.4344\n",
      "\n",
      "Epoch 00229: loss improved from 0.43533 to 0.43436, saving model to weights/weights-improvement-229-0.4344.hdf5\n",
      "Epoch 230/500\n",
      "479947/479947 [==============================] - 192s 400us/step - loss: 0.4351\n",
      "\n",
      "Epoch 00230: loss did not improve from 0.43436\n",
      "Epoch 231/500\n",
      "479947/479947 [==============================] - 192s 400us/step - loss: 0.4343\n",
      "\n",
      "Epoch 00231: loss improved from 0.43436 to 0.43427, saving model to weights/weights-improvement-231-0.4343.hdf5\n",
      "Epoch 232/500\n",
      "479947/479947 [==============================] - 191s 398us/step - loss: 0.4342\n",
      "\n",
      "Epoch 00232: loss improved from 0.43427 to 0.43419, saving model to weights/weights-improvement-232-0.4342.hdf5\n",
      "Epoch 233/500\n",
      "479947/479947 [==============================] - 193s 402us/step - loss: 0.4347\n",
      "\n",
      "Epoch 00233: loss did not improve from 0.43419\n",
      "Epoch 234/500\n",
      "479947/479947 [==============================] - 192s 401us/step - loss: 0.4334\n",
      "\n",
      "Epoch 00234: loss improved from 0.43419 to 0.43338, saving model to weights/weights-improvement-234-0.4334.hdf5\n",
      "Epoch 235/500\n",
      "479947/479947 [==============================] - 195s 405us/step - loss: 0.4334\n",
      "\n",
      "Epoch 00235: loss did not improve from 0.43338\n",
      "Epoch 236/500\n",
      "479947/479947 [==============================] - 194s 405us/step - loss: 0.4335\n",
      "\n",
      "Epoch 00236: loss did not improve from 0.43338\n",
      "Epoch 237/500\n",
      "479947/479947 [==============================] - 197s 411us/step - loss: 0.4333\n",
      "\n",
      "Epoch 00237: loss improved from 0.43338 to 0.43331, saving model to weights/weights-improvement-237-0.4333.hdf5\n",
      "Epoch 238/500\n",
      "479947/479947 [==============================] - 196s 408us/step - loss: 0.4334\n",
      "\n",
      "Epoch 00238: loss did not improve from 0.43331\n",
      "Epoch 239/500\n",
      "479947/479947 [==============================] - 193s 402us/step - loss: 0.4334\n",
      "\n",
      "Epoch 00239: loss did not improve from 0.43331\n",
      "Epoch 240/500\n",
      "479947/479947 [==============================] - 192s 401us/step - loss: 0.4329\n",
      "\n",
      "Epoch 00240: loss improved from 0.43331 to 0.43291, saving model to weights/weights-improvement-240-0.4329.hdf5\n",
      "Epoch 241/500\n",
      "479947/479947 [==============================] - 195s 406us/step - loss: 0.4327\n",
      "\n",
      "Epoch 00241: loss improved from 0.43291 to 0.43271, saving model to weights/weights-improvement-241-0.4327.hdf5\n",
      "Epoch 242/500\n",
      "479947/479947 [==============================] - 195s 407us/step - loss: 0.4319\n",
      "\n",
      "Epoch 00242: loss improved from 0.43271 to 0.43190, saving model to weights/weights-improvement-242-0.4319.hdf5\n",
      "Epoch 243/500\n",
      "479947/479947 [==============================] - 194s 404us/step - loss: 0.4328\n",
      "\n",
      "Epoch 00243: loss did not improve from 0.43190\n",
      "Epoch 244/500\n",
      "479947/479947 [==============================] - 195s 406us/step - loss: 0.4319\n",
      "\n",
      "Epoch 00244: loss did not improve from 0.43190\n",
      "Epoch 245/500\n",
      "479947/479947 [==============================] - 197s 411us/step - loss: 0.4321\n",
      "\n",
      "Epoch 00245: loss did not improve from 0.43190\n",
      "Epoch 246/500\n",
      "479947/479947 [==============================] - 196s 408us/step - loss: 0.4317\n",
      "\n",
      "Epoch 00246: loss improved from 0.43190 to 0.43174, saving model to weights/weights-improvement-246-0.4317.hdf5\n",
      "Epoch 247/500\n",
      "479947/479947 [==============================] - 197s 409us/step - loss: 0.4307\n",
      "\n",
      "Epoch 00247: loss improved from 0.43174 to 0.43066, saving model to weights/weights-improvement-247-0.4307.hdf5\n",
      "Epoch 248/500\n",
      "479947/479947 [==============================] - 197s 409us/step - loss: 0.4313\n",
      "\n",
      "Epoch 00248: loss did not improve from 0.43066\n",
      "Epoch 249/500\n",
      "479947/479947 [==============================] - 197s 410us/step - loss: 0.4304\n",
      "\n",
      "Epoch 00249: loss improved from 0.43066 to 0.43044, saving model to weights/weights-improvement-249-0.4304.hdf5\n",
      "Epoch 250/500\n",
      "479947/479947 [==============================] - 197s 410us/step - loss: 0.4298\n",
      "\n",
      "Epoch 00250: loss improved from 0.43044 to 0.42982, saving model to weights/weights-improvement-250-0.4298.hdf5\n",
      "Epoch 251/500\n",
      "479947/479947 [==============================] - 199s 414us/step - loss: 0.4306\n",
      "\n",
      "Epoch 00251: loss did not improve from 0.42982\n",
      "Epoch 252/500\n",
      "479947/479947 [==============================] - 199s 414us/step - loss: 0.4302\n",
      "\n",
      "Epoch 00252: loss did not improve from 0.42982\n",
      "Epoch 253/500\n",
      "479947/479947 [==============================] - 200s 416us/step - loss: 0.4298\n",
      "\n",
      "Epoch 00253: loss improved from 0.42982 to 0.42976, saving model to weights/weights-improvement-253-0.4298.hdf5\n",
      "Epoch 254/500\n",
      "479947/479947 [==============================] - 200s 417us/step - loss: 0.4305\n",
      "\n",
      "Epoch 00254: loss did not improve from 0.42976\n",
      "Epoch 255/500\n",
      "479947/479947 [==============================] - 200s 416us/step - loss: 0.4294\n",
      "\n",
      "Epoch 00255: loss improved from 0.42976 to 0.42944, saving model to weights/weights-improvement-255-0.4294.hdf5\n",
      "Epoch 256/500\n",
      "479947/479947 [==============================] - 196s 409us/step - loss: 0.4294\n",
      "\n",
      "Epoch 00256: loss improved from 0.42944 to 0.42941, saving model to weights/weights-improvement-256-0.4294.hdf5\n",
      "Epoch 257/500\n",
      "479947/479947 [==============================] - 197s 411us/step - loss: 0.4295\n",
      "\n",
      "Epoch 00257: loss did not improve from 0.42941\n",
      "Epoch 258/500\n",
      "479947/479947 [==============================] - 188s 391us/step - loss: 0.4291\n",
      "\n",
      "Epoch 00258: loss improved from 0.42941 to 0.42907, saving model to weights/weights-improvement-258-0.4291.hdf5\n",
      "Epoch 259/500\n",
      "479947/479947 [==============================] - 189s 394us/step - loss: 0.4286\n",
      "\n",
      "Epoch 00259: loss improved from 0.42907 to 0.42860, saving model to weights/weights-improvement-259-0.4286.hdf5\n",
      "Epoch 260/500\n",
      "479947/479947 [==============================] - 189s 393us/step - loss: 0.4283\n",
      "\n",
      "Epoch 00260: loss improved from 0.42860 to 0.42829, saving model to weights/weights-improvement-260-0.4283.hdf5\n",
      "Epoch 261/500\n",
      "479947/479947 [==============================] - 189s 395us/step - loss: 0.4281\n",
      "\n",
      "Epoch 00261: loss improved from 0.42829 to 0.42808, saving model to weights/weights-improvement-261-0.4281.hdf5\n",
      "Epoch 262/500\n",
      "479947/479947 [==============================] - 193s 402us/step - loss: 0.4291\n",
      "\n",
      "Epoch 00262: loss did not improve from 0.42808\n",
      "Epoch 263/500\n",
      "479947/479947 [==============================] - 192s 400us/step - loss: 0.4287\n",
      "\n",
      "Epoch 00263: loss did not improve from 0.42808\n",
      "Epoch 264/500\n",
      "479947/479947 [==============================] - 192s 401us/step - loss: 0.4275\n",
      "\n",
      "Epoch 00264: loss improved from 0.42808 to 0.42751, saving model to weights/weights-improvement-264-0.4275.hdf5\n",
      "Epoch 265/500\n",
      "479947/479947 [==============================] - 193s 403us/step - loss: 0.4277\n",
      "\n",
      "Epoch 00265: loss did not improve from 0.42751\n",
      "Epoch 266/500\n",
      "479947/479947 [==============================] - 190s 395us/step - loss: 0.4278\n",
      "\n",
      "Epoch 00266: loss did not improve from 0.42751\n",
      "Epoch 267/500\n",
      "479947/479947 [==============================] - 190s 396us/step - loss: 0.4270\n",
      "\n",
      "Epoch 00267: loss improved from 0.42751 to 0.42700, saving model to weights/weights-improvement-267-0.4270.hdf5\n",
      "Epoch 268/500\n",
      "479947/479947 [==============================] - 191s 398us/step - loss: 0.4266\n",
      "\n",
      "Epoch 00268: loss improved from 0.42700 to 0.42662, saving model to weights/weights-improvement-268-0.4266.hdf5\n",
      "Epoch 269/500\n",
      "479947/479947 [==============================] - 191s 399us/step - loss: 0.4272\n",
      "\n",
      "Epoch 00269: loss did not improve from 0.42662\n",
      "Epoch 270/500\n",
      "479947/479947 [==============================] - 190s 396us/step - loss: 0.4265\n",
      "\n",
      "Epoch 00270: loss improved from 0.42662 to 0.42653, saving model to weights/weights-improvement-270-0.4265.hdf5\n",
      "Epoch 271/500\n",
      "479947/479947 [==============================] - 191s 399us/step - loss: 0.4261\n",
      "\n",
      "Epoch 00271: loss improved from 0.42653 to 0.42607, saving model to weights/weights-improvement-271-0.4261.hdf5\n",
      "Epoch 272/500\n",
      "479947/479947 [==============================] - 193s 402us/step - loss: 0.4274\n",
      "\n",
      "Epoch 00272: loss did not improve from 0.42607\n",
      "Epoch 273/500\n",
      "479947/479947 [==============================] - 192s 400us/step - loss: 0.4266\n",
      "\n",
      "Epoch 00273: loss did not improve from 0.42607\n",
      "Epoch 274/500\n",
      "479947/479947 [==============================] - 193s 402us/step - loss: 0.4251\n",
      "\n",
      "Epoch 00274: loss improved from 0.42607 to 0.42511, saving model to weights/weights-improvement-274-0.4251.hdf5\n",
      "Epoch 275/500\n",
      "479947/479947 [==============================] - 193s 403us/step - loss: 0.4269\n",
      "\n",
      "Epoch 00275: loss did not improve from 0.42511\n",
      "Epoch 276/500\n",
      "479947/479947 [==============================] - 193s 401us/step - loss: 0.4257\n",
      "\n",
      "Epoch 00276: loss did not improve from 0.42511\n",
      "Epoch 277/500\n",
      "479947/479947 [==============================] - 192s 400us/step - loss: 0.4254\n",
      "\n",
      "Epoch 00277: loss did not improve from 0.42511\n",
      "Epoch 278/500\n",
      "479947/479947 [==============================] - 192s 401us/step - loss: 0.4253\n",
      "\n",
      "Epoch 00278: loss did not improve from 0.42511\n",
      "Epoch 279/500\n",
      "479947/479947 [==============================] - 193s 402us/step - loss: 0.4252\n",
      "\n",
      "Epoch 00279: loss did not improve from 0.42511\n",
      "Epoch 280/500\n",
      "479947/479947 [==============================] - 192s 401us/step - loss: 0.4255\n",
      "\n",
      "Epoch 00280: loss did not improve from 0.42511\n",
      "Epoch 281/500\n",
      "479947/479947 [==============================] - 192s 401us/step - loss: 0.4251\n",
      "\n",
      "Epoch 00281: loss did not improve from 0.42511\n",
      "Epoch 282/500\n",
      "479947/479947 [==============================] - 193s 402us/step - loss: 0.4246\n",
      "\n",
      "Epoch 00282: loss improved from 0.42511 to 0.42463, saving model to weights/weights-improvement-282-0.4246.hdf5\n",
      "Epoch 283/500\n",
      "479947/479947 [==============================] - 196s 409us/step - loss: 0.4247\n",
      "\n",
      "Epoch 00283: loss did not improve from 0.42463\n",
      "Epoch 284/500\n",
      "479947/479947 [==============================] - 195s 406us/step - loss: 0.4241\n",
      "\n",
      "Epoch 00284: loss improved from 0.42463 to 0.42413, saving model to weights/weights-improvement-284-0.4241.hdf5\n",
      "Epoch 285/500\n",
      "479947/479947 [==============================] - 194s 403us/step - loss: 0.4251\n",
      "\n",
      "Epoch 00285: loss did not improve from 0.42413\n",
      "Epoch 286/500\n",
      "479947/479947 [==============================] - 193s 403us/step - loss: 0.4239\n",
      "\n",
      "Epoch 00286: loss improved from 0.42413 to 0.42391, saving model to weights/weights-improvement-286-0.4239.hdf5\n",
      "Epoch 287/500\n",
      "479947/479947 [==============================] - 194s 405us/step - loss: 0.4237\n",
      "\n",
      "Epoch 00287: loss improved from 0.42391 to 0.42372, saving model to weights/weights-improvement-287-0.4237.hdf5\n",
      "Epoch 288/500\n",
      "479947/479947 [==============================] - 194s 405us/step - loss: 0.4239\n",
      "\n",
      "Epoch 00288: loss did not improve from 0.42372\n",
      "Epoch 289/500\n",
      "479947/479947 [==============================] - 193s 403us/step - loss: 0.4231\n",
      "\n",
      "Epoch 00289: loss improved from 0.42372 to 0.42308, saving model to weights/weights-improvement-289-0.4231.hdf5\n",
      "Epoch 290/500\n",
      "479947/479947 [==============================] - 195s 406us/step - loss: 0.4240\n",
      "\n",
      "Epoch 00290: loss did not improve from 0.42308\n",
      "Epoch 291/500\n",
      "479947/479947 [==============================] - 196s 408us/step - loss: 0.4230\n",
      "\n",
      "Epoch 00291: loss improved from 0.42308 to 0.42299, saving model to weights/weights-improvement-291-0.4230.hdf5\n",
      "Epoch 292/500\n",
      "479947/479947 [==============================] - 196s 408us/step - loss: 0.4232\n",
      "\n",
      "Epoch 00292: loss did not improve from 0.42299\n",
      "Epoch 293/500\n",
      "479947/479947 [==============================] - 197s 411us/step - loss: 0.4230\n",
      "\n",
      "Epoch 00293: loss did not improve from 0.42299\n",
      "Epoch 294/500\n",
      "479947/479947 [==============================] - 195s 406us/step - loss: 0.4229\n",
      "\n",
      "Epoch 00294: loss improved from 0.42299 to 0.42288, saving model to weights/weights-improvement-294-0.4229.hdf5\n",
      "Epoch 295/500\n",
      "479947/479947 [==============================] - 197s 410us/step - loss: 0.4223\n",
      "\n",
      "Epoch 00295: loss improved from 0.42288 to 0.42230, saving model to weights/weights-improvement-295-0.4223.hdf5\n",
      "Epoch 296/500\n",
      "479947/479947 [==============================] - 198s 413us/step - loss: 0.4220\n",
      "\n",
      "Epoch 00296: loss improved from 0.42230 to 0.42205, saving model to weights/weights-improvement-296-0.4220.hdf5\n",
      "Epoch 297/500\n",
      "479947/479947 [==============================] - 196s 408us/step - loss: 0.4226\n",
      "\n",
      "Epoch 00297: loss did not improve from 0.42205\n",
      "Epoch 298/500\n",
      "479947/479947 [==============================] - 196s 409us/step - loss: 0.4213\n",
      "\n",
      "Epoch 00298: loss improved from 0.42205 to 0.42127, saving model to weights/weights-improvement-298-0.4213.hdf5\n",
      "Epoch 299/500\n",
      "479947/479947 [==============================] - 198s 412us/step - loss: 0.4224\n",
      "\n",
      "Epoch 00299: loss did not improve from 0.42127\n",
      "Epoch 300/500\n",
      "479947/479947 [==============================] - 198s 412us/step - loss: 0.4215\n",
      "\n",
      "Epoch 00300: loss did not improve from 0.42127\n",
      "Epoch 301/500\n",
      "479947/479947 [==============================] - 200s 417us/step - loss: 0.4221\n",
      "\n",
      "Epoch 00301: loss did not improve from 0.42127\n",
      "Epoch 302/500\n",
      "479947/479947 [==============================] - 199s 415us/step - loss: 0.4210\n",
      "\n",
      "Epoch 00302: loss improved from 0.42127 to 0.42104, saving model to weights/weights-improvement-302-0.4210.hdf5\n",
      "Epoch 303/500\n",
      "479947/479947 [==============================] - 197s 410us/step - loss: 0.4216\n",
      "\n",
      "Epoch 00303: loss did not improve from 0.42104\n",
      "Epoch 304/500\n",
      "479947/479947 [==============================] - 196s 409us/step - loss: 0.4219\n",
      "\n",
      "Epoch 00304: loss did not improve from 0.42104\n",
      "Epoch 305/500\n",
      "479947/479947 [==============================] - 198s 413us/step - loss: 0.4215\n",
      "\n",
      "Epoch 00305: loss did not improve from 0.42104\n",
      "Epoch 306/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "479947/479947 [==============================] - 188s 391us/step - loss: 0.4212\n",
      "\n",
      "Epoch 00306: loss did not improve from 0.42104\n",
      "Epoch 307/500\n",
      "479947/479947 [==============================] - 189s 394us/step - loss: 0.4212\n",
      "\n",
      "Epoch 00307: loss did not improve from 0.42104\n",
      "Epoch 308/500\n",
      "479947/479947 [==============================] - 189s 394us/step - loss: 0.4208\n",
      "\n",
      "Epoch 00308: loss improved from 0.42104 to 0.42082, saving model to weights/weights-improvement-308-0.4208.hdf5\n",
      "Epoch 309/500\n",
      "479947/479947 [==============================] - 189s 393us/step - loss: 0.4207\n",
      "\n",
      "Epoch 00309: loss improved from 0.42082 to 0.42068, saving model to weights/weights-improvement-309-0.4207.hdf5\n",
      "Epoch 310/500\n",
      "479947/479947 [==============================] - 189s 395us/step - loss: 0.4197\n",
      "\n",
      "Epoch 00310: loss improved from 0.42068 to 0.41972, saving model to weights/weights-improvement-310-0.4197.hdf5\n",
      "Epoch 311/500\n",
      "479947/479947 [==============================] - 190s 397us/step - loss: 0.4204\n",
      "\n",
      "Epoch 00311: loss did not improve from 0.41972\n",
      "Epoch 312/500\n",
      "479947/479947 [==============================] - 190s 397us/step - loss: 0.4199\n",
      "\n",
      "Epoch 00312: loss did not improve from 0.41972\n",
      "Epoch 313/500\n",
      "479947/479947 [==============================] - 189s 395us/step - loss: 0.4208\n",
      "\n",
      "Epoch 00313: loss did not improve from 0.41972\n",
      "Epoch 314/500\n",
      "479947/479947 [==============================] - 191s 398us/step - loss: 0.4193\n",
      "\n",
      "Epoch 00314: loss improved from 0.41972 to 0.41928, saving model to weights/weights-improvement-314-0.4193.hdf5\n",
      "Epoch 315/500\n",
      "479947/479947 [==============================] - 192s 400us/step - loss: 0.4198\n",
      "\n",
      "Epoch 00315: loss did not improve from 0.41928\n",
      "Epoch 316/500\n",
      "479947/479947 [==============================] - 190s 397us/step - loss: 0.4192\n",
      "\n",
      "Epoch 00316: loss improved from 0.41928 to 0.41922, saving model to weights/weights-improvement-316-0.4192.hdf5\n",
      "Epoch 317/500\n",
      "479947/479947 [==============================] - 190s 397us/step - loss: 0.4190\n",
      "\n",
      "Epoch 00317: loss improved from 0.41922 to 0.41899, saving model to weights/weights-improvement-317-0.4190.hdf5\n",
      "Epoch 318/500\n",
      "479947/479947 [==============================] - 191s 399us/step - loss: 0.4191\n",
      "\n",
      "Epoch 00318: loss did not improve from 0.41899\n",
      "Epoch 319/500\n",
      "479947/479947 [==============================] - 191s 398us/step - loss: 0.4184\n",
      "\n",
      "Epoch 00319: loss improved from 0.41899 to 0.41840, saving model to weights/weights-improvement-319-0.4184.hdf5\n",
      "Epoch 320/500\n",
      "479947/479947 [==============================] - 197s 410us/step - loss: 0.4184\n",
      "\n",
      "Epoch 00320: loss improved from 0.41840 to 0.41840, saving model to weights/weights-improvement-320-0.4184.hdf5\n",
      "Epoch 321/500\n",
      "479947/479947 [==============================] - 195s 407us/step - loss: 0.4186\n",
      "\n",
      "Epoch 00321: loss did not improve from 0.41840\n",
      "Epoch 322/500\n",
      "479947/479947 [==============================] - 192s 400us/step - loss: 0.4185\n",
      "\n",
      "Epoch 00322: loss did not improve from 0.41840\n",
      "Epoch 323/500\n",
      "479947/479947 [==============================] - 193s 402us/step - loss: 0.4185\n",
      "\n",
      "Epoch 00323: loss did not improve from 0.41840\n",
      "Epoch 324/500\n",
      "479947/479947 [==============================] - 193s 403us/step - loss: 0.4184\n",
      "\n",
      "Epoch 00324: loss improved from 0.41840 to 0.41837, saving model to weights/weights-improvement-324-0.4184.hdf5\n",
      "Epoch 325/500\n",
      "479947/479947 [==============================] - 195s 407us/step - loss: 0.4184\n",
      "\n",
      "Epoch 00325: loss did not improve from 0.41837\n",
      "Epoch 326/500\n",
      "479947/479947 [==============================] - 194s 403us/step - loss: 0.4172\n",
      "\n",
      "Epoch 00326: loss improved from 0.41837 to 0.41720, saving model to weights/weights-improvement-326-0.4172.hdf5\n",
      "Epoch 327/500\n",
      "479947/479947 [==============================] - 194s 405us/step - loss: 0.4182\n",
      "\n",
      "Epoch 00327: loss did not improve from 0.41720\n",
      "Epoch 328/500\n",
      "479947/479947 [==============================] - 194s 403us/step - loss: 0.4172\n",
      "\n",
      "Epoch 00328: loss improved from 0.41720 to 0.41717, saving model to weights/weights-improvement-328-0.4172.hdf5\n",
      "Epoch 329/500\n",
      "479947/479947 [==============================] - 196s 409us/step - loss: 0.4182\n",
      "\n",
      "Epoch 00329: loss did not improve from 0.41717\n",
      "Epoch 330/500\n",
      "479947/479947 [==============================] - 196s 408us/step - loss: 0.4175\n",
      "\n",
      "Epoch 00330: loss did not improve from 0.41717\n",
      "Epoch 331/500\n",
      "479947/479947 [==============================] - 193s 403us/step - loss: 0.4178\n",
      "\n",
      "Epoch 00331: loss did not improve from 0.41717\n",
      "Epoch 332/500\n",
      "479947/479947 [==============================] - 193s 403us/step - loss: 0.4166\n",
      "\n",
      "Epoch 00332: loss improved from 0.41717 to 0.41659, saving model to weights/weights-improvement-332-0.4166.hdf5\n",
      "Epoch 333/500\n",
      "479947/479947 [==============================] - 195s 407us/step - loss: 0.4168\n",
      "\n",
      "Epoch 00333: loss did not improve from 0.41659\n",
      "Epoch 334/500\n",
      "479947/479947 [==============================] - 195s 406us/step - loss: 0.4171\n",
      "\n",
      "Epoch 00334: loss did not improve from 0.41659\n",
      "Epoch 335/500\n",
      "479947/479947 [==============================] - 194s 404us/step - loss: 0.4169\n",
      "\n",
      "Epoch 00335: loss did not improve from 0.41659\n",
      "Epoch 336/500\n",
      "479947/479947 [==============================] - 195s 406us/step - loss: 0.4171\n",
      "\n",
      "Epoch 00336: loss did not improve from 0.41659\n",
      "Epoch 337/500\n",
      "479947/479947 [==============================] - 197s 410us/step - loss: 0.4161\n",
      "\n",
      "Epoch 00337: loss improved from 0.41659 to 0.41607, saving model to weights/weights-improvement-337-0.4161.hdf5\n",
      "Epoch 338/500\n",
      "479947/479947 [==============================] - 196s 409us/step - loss: 0.4169\n",
      "\n",
      "Epoch 00338: loss did not improve from 0.41607\n",
      "Epoch 339/500\n",
      "479947/479947 [==============================] - 199s 415us/step - loss: 0.4161\n",
      "\n",
      "Epoch 00339: loss improved from 0.41607 to 0.41607, saving model to weights/weights-improvement-339-0.4161.hdf5\n",
      "Epoch 340/500\n",
      "479947/479947 [==============================] - 198s 412us/step - loss: 0.4166\n",
      "\n",
      "Epoch 00340: loss did not improve from 0.41607\n",
      "Epoch 341/500\n",
      "479947/479947 [==============================] - 195s 406us/step - loss: 0.4158\n",
      "\n",
      "Epoch 00341: loss improved from 0.41607 to 0.41582, saving model to weights/weights-improvement-341-0.4158.hdf5\n",
      "Epoch 342/500\n",
      "479947/479947 [==============================] - 197s 409us/step - loss: 0.4160\n",
      "\n",
      "Epoch 00342: loss did not improve from 0.41582\n",
      "Epoch 343/500\n",
      "479947/479947 [==============================] - 195s 407us/step - loss: 0.4161\n",
      "\n",
      "Epoch 00343: loss did not improve from 0.41582\n",
      "Epoch 344/500\n",
      "479947/479947 [==============================] - 196s 409us/step - loss: 0.4158\n",
      "\n",
      "Epoch 00344: loss did not improve from 0.41582\n",
      "Epoch 345/500\n",
      "479947/479947 [==============================] - 196s 409us/step - loss: 0.4158\n",
      "\n",
      "Epoch 00345: loss improved from 0.41582 to 0.41578, saving model to weights/weights-improvement-345-0.4158.hdf5\n",
      "Epoch 346/500\n",
      "479947/479947 [==============================] - 196s 408us/step - loss: 0.4151\n",
      "\n",
      "Epoch 00346: loss improved from 0.41578 to 0.41513, saving model to weights/weights-improvement-346-0.4151.hdf5\n",
      "Epoch 347/500\n",
      "479947/479947 [==============================] - 199s 414us/step - loss: 0.4156\n",
      "\n",
      "Epoch 00347: loss did not improve from 0.41513\n",
      "Epoch 348/500\n",
      "479947/479947 [==============================] - 197s 410us/step - loss: 0.4161\n",
      "\n",
      "Epoch 00348: loss did not improve from 0.41513\n",
      "Epoch 349/500\n",
      "479947/479947 [==============================] - 199s 414us/step - loss: 0.4145\n",
      "\n",
      "Epoch 00349: loss improved from 0.41513 to 0.41447, saving model to weights/weights-improvement-349-0.4145.hdf5\n",
      "Epoch 350/500\n",
      "479947/479947 [==============================] - 198s 413us/step - loss: 0.4160\n",
      "\n",
      "Epoch 00350: loss did not improve from 0.41447\n",
      "Epoch 351/500\n",
      "479947/479947 [==============================] - 199s 415us/step - loss: 0.4147\n",
      "\n",
      "Epoch 00351: loss did not improve from 0.41447\n",
      "Epoch 352/500\n",
      "479947/479947 [==============================] - 199s 414us/step - loss: 0.4155\n",
      "\n",
      "Epoch 00352: loss did not improve from 0.41447\n",
      "Epoch 353/500\n",
      "479947/479947 [==============================] - 198s 412us/step - loss: 0.4152\n",
      "\n",
      "Epoch 00353: loss did not improve from 0.41447\n",
      "Epoch 354/500\n",
      "479947/479947 [==============================] - 198s 414us/step - loss: 0.4146\n",
      "\n",
      "Epoch 00354: loss did not improve from 0.41447\n",
      "Epoch 355/500\n",
      "479947/479947 [==============================] - 188s 392us/step - loss: 0.4145\n",
      "\n",
      "Epoch 00355: loss did not improve from 0.41447\n",
      "Epoch 356/500\n",
      "479947/479947 [==============================] - 189s 394us/step - loss: 0.4138\n",
      "\n",
      "Epoch 00356: loss improved from 0.41447 to 0.41380, saving model to weights/weights-improvement-356-0.4138.hdf5\n",
      "Epoch 357/500\n",
      "479947/479947 [==============================] - 190s 397us/step - loss: 0.4144\n",
      "\n",
      "Epoch 00357: loss did not improve from 0.41380\n",
      "Epoch 358/500\n",
      "479947/479947 [==============================] - 193s 403us/step - loss: 0.4148\n",
      "\n",
      "Epoch 00358: loss did not improve from 0.41380\n",
      "Epoch 359/500\n",
      "479947/479947 [==============================] - 191s 398us/step - loss: 0.4135\n",
      "\n",
      "Epoch 00359: loss improved from 0.41380 to 0.41349, saving model to weights/weights-improvement-359-0.4135.hdf5\n",
      "Epoch 360/500\n",
      "479947/479947 [==============================] - 190s 395us/step - loss: 0.4143\n",
      "\n",
      "Epoch 00360: loss did not improve from 0.41349\n",
      "Epoch 361/500\n",
      "479947/479947 [==============================] - 190s 396us/step - loss: 0.4141\n",
      "\n",
      "Epoch 00361: loss did not improve from 0.41349\n",
      "Epoch 362/500\n",
      "479947/479947 [==============================] - 197s 410us/step - loss: 0.4134\n",
      "\n",
      "Epoch 00362: loss improved from 0.41349 to 0.41337, saving model to weights/weights-improvement-362-0.4134.hdf5\n",
      "Epoch 363/500\n",
      "479947/479947 [==============================] - 196s 409us/step - loss: 0.4139\n",
      "\n",
      "Epoch 00363: loss did not improve from 0.41337\n",
      "Epoch 364/500\n",
      "479947/479947 [==============================] - 195s 406us/step - loss: 0.4131\n",
      "\n",
      "Epoch 00364: loss improved from 0.41337 to 0.41305, saving model to weights/weights-improvement-364-0.4131.hdf5\n",
      "Epoch 365/500\n",
      "479947/479947 [==============================] - 196s 409us/step - loss: 0.4131\n",
      "\n",
      "Epoch 00365: loss did not improve from 0.41305\n",
      "Epoch 366/500\n",
      "479947/479947 [==============================] - 196s 408us/step - loss: 0.4138\n",
      "\n",
      "Epoch 00366: loss did not improve from 0.41305\n",
      "Epoch 367/500\n",
      "479947/479947 [==============================] - 198s 412us/step - loss: 0.4122\n",
      "\n",
      "Epoch 00367: loss improved from 0.41305 to 0.41224, saving model to weights/weights-improvement-367-0.4122.hdf5\n",
      "Epoch 368/500\n",
      "479947/479947 [==============================] - 196s 409us/step - loss: 0.4138\n",
      "\n",
      "Epoch 00368: loss did not improve from 0.41224\n",
      "Epoch 369/500\n",
      "479947/479947 [==============================] - 197s 410us/step - loss: 0.4134\n",
      "\n",
      "Epoch 00369: loss did not improve from 0.41224\n",
      "Epoch 370/500\n",
      "479947/479947 [==============================] - 195s 407us/step - loss: 0.4136\n",
      "\n",
      "Epoch 00370: loss did not improve from 0.41224\n",
      "Epoch 371/500\n",
      "479947/479947 [==============================] - 192s 401us/step - loss: 0.4121\n",
      "\n",
      "Epoch 00371: loss improved from 0.41224 to 0.41212, saving model to weights/weights-improvement-371-0.4121.hdf5\n",
      "Epoch 372/500\n",
      "479947/479947 [==============================] - 193s 402us/step - loss: 0.4128\n",
      "\n",
      "Epoch 00372: loss did not improve from 0.41212\n",
      "Epoch 373/500\n",
      "479947/479947 [==============================] - 193s 403us/step - loss: 0.4131\n",
      "\n",
      "Epoch 00373: loss did not improve from 0.41212\n",
      "Epoch 374/500\n",
      "479947/479947 [==============================] - 193s 402us/step - loss: 0.4129\n",
      "\n",
      "Epoch 00374: loss did not improve from 0.41212\n",
      "Epoch 375/500\n",
      "479947/479947 [==============================] - 194s 403us/step - loss: 0.4124\n",
      "\n",
      "Epoch 00375: loss did not improve from 0.41212\n",
      "Epoch 376/500\n",
      "479947/479947 [==============================] - 195s 407us/step - loss: 0.4120\n",
      "\n",
      "Epoch 00376: loss improved from 0.41212 to 0.41197, saving model to weights/weights-improvement-376-0.4120.hdf5\n",
      "Epoch 377/500\n",
      "479947/479947 [==============================] - 193s 402us/step - loss: 0.4130\n",
      "\n",
      "Epoch 00377: loss did not improve from 0.41197\n",
      "Epoch 378/500\n",
      "479947/479947 [==============================] - 191s 398us/step - loss: 0.4112\n",
      "\n",
      "Epoch 00378: loss improved from 0.41197 to 0.41120, saving model to weights/weights-improvement-378-0.4112.hdf5\n",
      "Epoch 379/500\n",
      "479947/479947 [==============================] - 192s 400us/step - loss: 0.4124\n",
      "\n",
      "Epoch 00379: loss did not improve from 0.41120\n",
      "Epoch 380/500\n",
      "479947/479947 [==============================] - 194s 404us/step - loss: 0.4110\n",
      "\n",
      "Epoch 00380: loss improved from 0.41120 to 0.41105, saving model to weights/weights-improvement-380-0.4110.hdf5\n",
      "Epoch 381/500\n",
      "479947/479947 [==============================] - 210s 439us/step - loss: 0.4115\n",
      "\n",
      "Epoch 00381: loss did not improve from 0.41105\n",
      "Epoch 382/500\n",
      "479947/479947 [==============================] - 203s 423us/step - loss: 0.4107\n",
      "\n",
      "Epoch 00382: loss improved from 0.41105 to 0.41074, saving model to weights/weights-improvement-382-0.4107.hdf5\n",
      "Epoch 383/500\n",
      "479947/479947 [==============================] - 205s 426us/step - loss: 0.4110\n",
      "\n",
      "Epoch 00383: loss did not improve from 0.41074\n",
      "Epoch 384/500\n",
      "479947/479947 [==============================] - 203s 423us/step - loss: 0.4112\n",
      "\n",
      "Epoch 00384: loss did not improve from 0.41074\n",
      "Epoch 385/500\n",
      "479947/479947 [==============================] - 205s 427us/step - loss: 0.4101\n",
      "\n",
      "Epoch 00385: loss improved from 0.41074 to 0.41012, saving model to weights/weights-improvement-385-0.4101.hdf5\n",
      "Epoch 386/500\n",
      "479947/479947 [==============================] - 205s 427us/step - loss: 0.4115\n",
      "\n",
      "Epoch 00386: loss did not improve from 0.41012\n",
      "Epoch 387/500\n",
      "479947/479947 [==============================] - 204s 425us/step - loss: 0.4104\n",
      "\n",
      "Epoch 00387: loss did not improve from 0.41012\n",
      "Epoch 388/500\n",
      "479947/479947 [==============================] - 204s 425us/step - loss: 0.4104\n",
      "\n",
      "Epoch 00388: loss did not improve from 0.41012\n",
      "Epoch 389/500\n",
      "479947/479947 [==============================] - 204s 426us/step - loss: 0.4111\n",
      "\n",
      "Epoch 00389: loss did not improve from 0.41012\n",
      "Epoch 390/500\n",
      "479947/479947 [==============================] - 205s 427us/step - loss: 0.4117\n",
      "\n",
      "Epoch 00390: loss did not improve from 0.41012\n",
      "Epoch 391/500\n",
      "479947/479947 [==============================] - 203s 422us/step - loss: 0.4094\n",
      "\n",
      "Epoch 00391: loss improved from 0.41012 to 0.40943, saving model to weights/weights-improvement-391-0.4094.hdf5\n",
      "Epoch 392/500\n",
      "479947/479947 [==============================] - 203s 422us/step - loss: 0.4107\n",
      "\n",
      "Epoch 00392: loss did not improve from 0.40943\n",
      "Epoch 393/500\n",
      "479947/479947 [==============================] - 204s 426us/step - loss: 0.4106\n",
      "\n",
      "Epoch 00393: loss did not improve from 0.40943\n",
      "Epoch 394/500\n",
      "479947/479947 [==============================] - 204s 424us/step - loss: 0.4102\n",
      "\n",
      "Epoch 00394: loss did not improve from 0.40943\n",
      "Epoch 395/500\n",
      "479947/479947 [==============================] - 202s 422us/step - loss: 0.4101\n",
      "\n",
      "Epoch 00395: loss did not improve from 0.40943\n",
      "Epoch 396/500\n",
      "479947/479947 [==============================] - 204s 425us/step - loss: 0.4105\n",
      "\n",
      "Epoch 00396: loss did not improve from 0.40943\n",
      "Epoch 397/500\n",
      "479947/479947 [==============================] - 203s 423us/step - loss: 0.4094\n",
      "\n",
      "Epoch 00397: loss improved from 0.40943 to 0.40938, saving model to weights/weights-improvement-397-0.4094.hdf5\n",
      "Epoch 398/500\n",
      "479947/479947 [==============================] - 204s 425us/step - loss: 0.4095\n",
      "\n",
      "Epoch 00398: loss did not improve from 0.40938\n",
      "Epoch 399/500\n",
      "479947/479947 [==============================] - 202s 421us/step - loss: 0.4099\n",
      "\n",
      "Epoch 00399: loss did not improve from 0.40938\n",
      "Epoch 400/500\n",
      "479947/479947 [==============================] - 201s 419us/step - loss: 0.4091\n",
      "\n",
      "Epoch 00400: loss improved from 0.40938 to 0.40911, saving model to weights/weights-improvement-400-0.4091.hdf5\n",
      "Epoch 401/500\n",
      "479947/479947 [==============================] - 201s 419us/step - loss: 0.4098\n",
      "\n",
      "Epoch 00401: loss did not improve from 0.40911\n",
      "Epoch 402/500\n",
      "479947/479947 [==============================] - 204s 425us/step - loss: 0.4094\n",
      "\n",
      "Epoch 00402: loss did not improve from 0.40911\n",
      "Epoch 403/500\n",
      "479947/479947 [==============================] - 203s 423us/step - loss: 0.4094\n",
      "\n",
      "Epoch 00403: loss did not improve from 0.40911\n",
      "Epoch 404/500\n",
      "479947/479947 [==============================] - 202s 420us/step - loss: 0.4088\n",
      "\n",
      "Epoch 00404: loss improved from 0.40911 to 0.40884, saving model to weights/weights-improvement-404-0.4088.hdf5\n",
      "Epoch 405/500\n",
      "479947/479947 [==============================] - 202s 420us/step - loss: 0.4086\n",
      "\n",
      "Epoch 00405: loss improved from 0.40884 to 0.40863, saving model to weights/weights-improvement-405-0.4086.hdf5\n",
      "Epoch 406/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "479947/479947 [==============================] - 189s 394us/step - loss: 0.4096\n",
      "\n",
      "Epoch 00406: loss did not improve from 0.40863\n",
      "Epoch 407/500\n",
      "479947/479947 [==============================] - 189s 394us/step - loss: 0.4086\n",
      "\n",
      "Epoch 00407: loss improved from 0.40863 to 0.40856, saving model to weights/weights-improvement-407-0.4086.hdf5\n",
      "Epoch 408/500\n",
      "479947/479947 [==============================] - 189s 394us/step - loss: 0.4089\n",
      "\n",
      "Epoch 00408: loss did not improve from 0.40856\n",
      "Epoch 409/500\n",
      "479947/479947 [==============================] - 188s 392us/step - loss: 0.4088\n",
      "\n",
      "Epoch 00409: loss did not improve from 0.40856\n",
      "Epoch 410/500\n",
      "479947/479947 [==============================] - 189s 394us/step - loss: 0.4081\n",
      "\n",
      "Epoch 00410: loss improved from 0.40856 to 0.40810, saving model to weights/weights-improvement-410-0.4081.hdf5\n",
      "Epoch 411/500\n",
      "479947/479947 [==============================] - 191s 399us/step - loss: 0.4089\n",
      "\n",
      "Epoch 00411: loss did not improve from 0.40810\n",
      "Epoch 412/500\n",
      "479947/479947 [==============================] - 190s 397us/step - loss: 0.4087\n",
      "\n",
      "Epoch 00412: loss did not improve from 0.40810\n",
      "Epoch 413/500\n",
      "479947/479947 [==============================] - 190s 396us/step - loss: 0.4086\n",
      "\n",
      "Epoch 00413: loss did not improve from 0.40810\n",
      "Epoch 414/500\n",
      "479947/479947 [==============================] - 190s 395us/step - loss: 0.4076\n",
      "\n",
      "Epoch 00414: loss improved from 0.40810 to 0.40764, saving model to weights/weights-improvement-414-0.4076.hdf5\n",
      "Epoch 415/500\n",
      "479947/479947 [==============================] - 192s 400us/step - loss: 0.4091\n",
      "\n",
      "Epoch 00415: loss did not improve from 0.40764\n",
      "Epoch 416/500\n",
      "479947/479947 [==============================] - 201s 418us/step - loss: 0.4080\n",
      "\n",
      "Epoch 00416: loss did not improve from 0.40764\n",
      "Epoch 417/500\n",
      "479947/479947 [==============================] - 200s 417us/step - loss: 0.4071\n",
      "\n",
      "Epoch 00417: loss improved from 0.40764 to 0.40713, saving model to weights/weights-improvement-417-0.4071.hdf5\n",
      "Epoch 418/500\n",
      "479947/479947 [==============================] - 201s 418us/step - loss: 0.4087\n",
      "\n",
      "Epoch 00418: loss did not improve from 0.40713\n",
      "Epoch 419/500\n",
      "479947/479947 [==============================] - 200s 418us/step - loss: 0.4075\n",
      "\n",
      "Epoch 00419: loss did not improve from 0.40713\n",
      "Epoch 420/500\n",
      "479947/479947 [==============================] - 202s 421us/step - loss: 0.4083\n",
      "\n",
      "Epoch 00420: loss did not improve from 0.40713\n",
      "Epoch 421/500\n",
      "479947/479947 [==============================] - 202s 420us/step - loss: 0.4071\n",
      "\n",
      "Epoch 00421: loss improved from 0.40713 to 0.40707, saving model to weights/weights-improvement-421-0.4071.hdf5\n",
      "Epoch 422/500\n",
      "479947/479947 [==============================] - 202s 421us/step - loss: 0.4070\n",
      "\n",
      "Epoch 00422: loss improved from 0.40707 to 0.40698, saving model to weights/weights-improvement-422-0.4070.hdf5\n",
      "Epoch 423/500\n",
      "479947/479947 [==============================] - 202s 420us/step - loss: 0.4074\n",
      "\n",
      "Epoch 00423: loss did not improve from 0.40698\n",
      "Epoch 424/500\n",
      "479947/479947 [==============================] - 203s 423us/step - loss: 0.4075\n",
      "\n",
      "Epoch 00424: loss did not improve from 0.40698\n",
      "Epoch 425/500\n",
      "479947/479947 [==============================] - 204s 425us/step - loss: 0.4072\n",
      "\n",
      "Epoch 00425: loss did not improve from 0.40698\n",
      "Epoch 426/500\n",
      "479947/479947 [==============================] - 203s 424us/step - loss: 0.4064\n",
      "\n",
      "Epoch 00426: loss improved from 0.40698 to 0.40640, saving model to weights/weights-improvement-426-0.4064.hdf5\n",
      "Epoch 427/500\n",
      "479947/479947 [==============================] - 204s 425us/step - loss: 0.4074\n",
      "\n",
      "Epoch 00427: loss did not improve from 0.40640\n",
      "Epoch 428/500\n",
      "479947/479947 [==============================] - 205s 426us/step - loss: 0.4064\n",
      "\n",
      "Epoch 00428: loss did not improve from 0.40640\n",
      "Epoch 429/500\n",
      "479947/479947 [==============================] - 205s 428us/step - loss: 0.4067\n",
      "\n",
      "Epoch 00429: loss did not improve from 0.40640\n",
      "Epoch 430/500\n",
      "479947/479947 [==============================] - 204s 425us/step - loss: 0.4071\n",
      "\n",
      "Epoch 00430: loss did not improve from 0.40640\n",
      "Epoch 431/500\n",
      "479947/479947 [==============================] - 203s 423us/step - loss: 0.4071\n",
      "\n",
      "Epoch 00431: loss did not improve from 0.40640\n",
      "Epoch 432/500\n",
      "479947/479947 [==============================] - 203s 423us/step - loss: 0.4064\n",
      "\n",
      "Epoch 00432: loss improved from 0.40640 to 0.40636, saving model to weights/weights-improvement-432-0.4064.hdf5\n",
      "Epoch 433/500\n",
      "479947/479947 [==============================] - 204s 424us/step - loss: 0.4073\n",
      "\n",
      "Epoch 00433: loss did not improve from 0.40636\n",
      "Epoch 434/500\n",
      "479947/479947 [==============================] - 203s 423us/step - loss: 0.4061\n",
      "\n",
      "Epoch 00434: loss improved from 0.40636 to 0.40612, saving model to weights/weights-improvement-434-0.4061.hdf5\n",
      "Epoch 435/500\n",
      "479947/479947 [==============================] - 204s 425us/step - loss: 0.4057\n",
      "\n",
      "Epoch 00435: loss improved from 0.40612 to 0.40574, saving model to weights/weights-improvement-435-0.4057.hdf5\n",
      "Epoch 436/500\n",
      "479947/479947 [==============================] - 204s 425us/step - loss: 0.4064\n",
      "\n",
      "Epoch 00436: loss did not improve from 0.40574\n",
      "Epoch 437/500\n",
      "479947/479947 [==============================] - 204s 425us/step - loss: 0.4064\n",
      "\n",
      "Epoch 00437: loss did not improve from 0.40574\n",
      "Epoch 438/500\n",
      "479947/479947 [==============================] - 205s 427us/step - loss: 0.4058\n",
      "\n",
      "Epoch 00438: loss did not improve from 0.40574\n",
      "Epoch 439/500\n",
      "479947/479947 [==============================] - 205s 428us/step - loss: 0.4058\n",
      "\n",
      "Epoch 00439: loss did not improve from 0.40574\n",
      "Epoch 440/500\n",
      "479947/479947 [==============================] - 204s 426us/step - loss: 0.4065\n",
      "\n",
      "Epoch 00440: loss did not improve from 0.40574\n",
      "Epoch 441/500\n",
      "479947/479947 [==============================] - 206s 430us/step - loss: 0.4056\n",
      "\n",
      "Epoch 00441: loss improved from 0.40574 to 0.40556, saving model to weights/weights-improvement-441-0.4056.hdf5\n",
      "Epoch 442/500\n",
      "479947/479947 [==============================] - 206s 429us/step - loss: 0.4050\n",
      "\n",
      "Epoch 00442: loss improved from 0.40556 to 0.40499, saving model to weights/weights-improvement-442-0.4050.hdf5\n",
      "Epoch 443/500\n",
      "479947/479947 [==============================] - 206s 429us/step - loss: 0.4051\n",
      "\n",
      "Epoch 00443: loss did not improve from 0.40499\n",
      "Epoch 444/500\n",
      "479947/479947 [==============================] - 206s 428us/step - loss: 0.4054\n",
      "\n",
      "Epoch 00444: loss did not improve from 0.40499\n",
      "Epoch 445/500\n",
      "479947/479947 [==============================] - 204s 426us/step - loss: 0.4059\n",
      "\n",
      "Epoch 00445: loss did not improve from 0.40499\n",
      "Epoch 446/500\n",
      "479947/479947 [==============================] - 204s 425us/step - loss: 0.4060\n",
      "\n",
      "Epoch 00446: loss did not improve from 0.40499\n",
      "Epoch 447/500\n",
      "479947/479947 [==============================] - 206s 430us/step - loss: 0.4051\n",
      "\n",
      "Epoch 00447: loss did not improve from 0.40499\n",
      "Epoch 448/500\n",
      "479947/479947 [==============================] - 203s 424us/step - loss: 0.4046\n",
      "\n",
      "Epoch 00448: loss improved from 0.40499 to 0.40462, saving model to weights/weights-improvement-448-0.4046.hdf5\n",
      "Epoch 449/500\n",
      "479947/479947 [==============================] - 203s 422us/step - loss: 0.4050\n",
      "\n",
      "Epoch 00449: loss did not improve from 0.40462\n",
      "Epoch 450/500\n",
      "479947/479947 [==============================] - 204s 424us/step - loss: 0.4049\n",
      "\n",
      "Epoch 00450: loss did not improve from 0.40462\n",
      "Epoch 451/500\n",
      "479947/479947 [==============================] - 203s 424us/step - loss: 0.4056\n",
      "\n",
      "Epoch 00451: loss did not improve from 0.40462\n",
      "Epoch 452/500\n",
      "479947/479947 [==============================] - 203s 422us/step - loss: 0.4046\n",
      "\n",
      "Epoch 00452: loss did not improve from 0.40462\n",
      "Epoch 453/500\n",
      "479947/479947 [==============================] - 202s 421us/step - loss: 0.4046\n",
      "\n",
      "Epoch 00453: loss did not improve from 0.40462\n",
      "Epoch 454/500\n",
      "479947/479947 [==============================] - 201s 419us/step - loss: 0.4047\n",
      "\n",
      "Epoch 00454: loss did not improve from 0.40462\n",
      "Epoch 455/500\n",
      "479947/479947 [==============================] - 202s 420us/step - loss: 0.4047\n",
      "\n",
      "Epoch 00455: loss did not improve from 0.40462\n",
      "Epoch 456/500\n",
      "479947/479947 [==============================] - 204s 424us/step - loss: 0.4037\n",
      "\n",
      "Epoch 00456: loss improved from 0.40462 to 0.40369, saving model to weights/weights-improvement-456-0.4037.hdf5\n",
      "Epoch 457/500\n",
      "479947/479947 [==============================] - 189s 394us/step - loss: 0.4051\n",
      "\n",
      "Epoch 00457: loss did not improve from 0.40369\n",
      "Epoch 458/500\n",
      "479947/479947 [==============================] - 188s 391us/step - loss: 0.4043\n",
      "\n",
      "Epoch 00458: loss did not improve from 0.40369\n",
      "Epoch 459/500\n",
      "479947/479947 [==============================] - 188s 391us/step - loss: 0.4044\n",
      "\n",
      "Epoch 00459: loss did not improve from 0.40369\n",
      "Epoch 460/500\n",
      "479947/479947 [==============================] - 188s 392us/step - loss: 0.4046\n",
      "\n",
      "Epoch 00460: loss did not improve from 0.40369\n",
      "Epoch 461/500\n",
      "479947/479947 [==============================] - 189s 393us/step - loss: 0.4042\n",
      "\n",
      "Epoch 00461: loss did not improve from 0.40369\n",
      "Epoch 462/500\n",
      "479947/479947 [==============================] - 189s 393us/step - loss: 0.4042\n",
      "\n",
      "Epoch 00462: loss did not improve from 0.40369\n",
      "Epoch 463/500\n",
      "479947/479947 [==============================] - 190s 395us/step - loss: 0.4039\n",
      "\n",
      "Epoch 00463: loss did not improve from 0.40369\n",
      "Epoch 464/500\n",
      "479947/479947 [==============================] - 190s 396us/step - loss: 0.4035\n",
      "\n",
      "Epoch 00464: loss improved from 0.40369 to 0.40345, saving model to weights/weights-improvement-464-0.4035.hdf5\n",
      "Epoch 465/500\n",
      "479947/479947 [==============================] - 194s 404us/step - loss: 0.4043\n",
      "\n",
      "Epoch 00465: loss did not improve from 0.40345\n",
      "Epoch 466/500\n",
      "479947/479947 [==============================] - 191s 398us/step - loss: 0.4040\n",
      "\n",
      "Epoch 00466: loss did not improve from 0.40345\n",
      "Epoch 467/500\n",
      "479947/479947 [==============================] - 190s 396us/step - loss: 0.4038\n",
      "\n",
      "Epoch 00467: loss did not improve from 0.40345\n",
      "Epoch 468/500\n",
      "479947/479947 [==============================] - 190s 397us/step - loss: 0.4043\n",
      "\n",
      "Epoch 00468: loss did not improve from 0.40345\n",
      "Epoch 469/500\n",
      "479947/479947 [==============================] - 191s 398us/step - loss: 0.4035\n",
      "\n",
      "Epoch 00469: loss did not improve from 0.40345\n",
      "Epoch 470/500\n",
      "479947/479947 [==============================] - 191s 398us/step - loss: 0.4037\n",
      "\n",
      "Epoch 00470: loss did not improve from 0.40345\n",
      "Epoch 471/500\n",
      "479947/479947 [==============================] - 191s 399us/step - loss: 0.4030\n",
      "\n",
      "Epoch 00471: loss improved from 0.40345 to 0.40300, saving model to weights/weights-improvement-471-0.4030.hdf5\n",
      "Epoch 472/500\n",
      "479947/479947 [==============================] - 192s 400us/step - loss: 0.4031\n",
      "\n",
      "Epoch 00472: loss did not improve from 0.40300\n",
      "Epoch 473/500\n",
      "479947/479947 [==============================] - 191s 398us/step - loss: 0.4028\n",
      "\n",
      "Epoch 00473: loss improved from 0.40300 to 0.40279, saving model to weights/weights-improvement-473-0.4028.hdf5\n",
      "Epoch 474/500\n",
      "479947/479947 [==============================] - 193s 401us/step - loss: 0.4032\n",
      "\n",
      "Epoch 00474: loss did not improve from 0.40279\n",
      "Epoch 475/500\n",
      "479947/479947 [==============================] - 195s 406us/step - loss: 0.4031\n",
      "\n",
      "Epoch 00475: loss did not improve from 0.40279\n",
      "Epoch 476/500\n",
      "479947/479947 [==============================] - 191s 399us/step - loss: 0.4027\n",
      "\n",
      "Epoch 00476: loss improved from 0.40279 to 0.40269, saving model to weights/weights-improvement-476-0.4027.hdf5\n",
      "Epoch 477/500\n",
      "479947/479947 [==============================] - 192s 400us/step - loss: 0.4026\n",
      "\n",
      "Epoch 00477: loss improved from 0.40269 to 0.40258, saving model to weights/weights-improvement-477-0.4026.hdf5\n",
      "Epoch 478/500\n",
      "479947/479947 [==============================] - 191s 399us/step - loss: 0.4028\n",
      "\n",
      "Epoch 00478: loss did not improve from 0.40258\n",
      "Epoch 479/500\n",
      "479947/479947 [==============================] - 193s 401us/step - loss: 0.4029\n",
      "\n",
      "Epoch 00479: loss did not improve from 0.40258\n",
      "Epoch 480/500\n",
      "479947/479947 [==============================] - 193s 401us/step - loss: 0.4028\n",
      "\n",
      "Epoch 00480: loss did not improve from 0.40258\n",
      "Epoch 481/500\n",
      "479947/479947 [==============================] - 193s 402us/step - loss: 0.4026\n",
      "\n",
      "Epoch 00481: loss did not improve from 0.40258\n",
      "Epoch 482/500\n",
      "479947/479947 [==============================] - 193s 401us/step - loss: 0.4023\n",
      "\n",
      "Epoch 00482: loss improved from 0.40258 to 0.40233, saving model to weights/weights-improvement-482-0.4023.hdf5\n",
      "Epoch 483/500\n",
      "479947/479947 [==============================] - 192s 400us/step - loss: 0.4015\n",
      "\n",
      "Epoch 00483: loss improved from 0.40233 to 0.40150, saving model to weights/weights-improvement-483-0.4015.hdf5\n",
      "Epoch 484/500\n",
      "479947/479947 [==============================] - 197s 411us/step - loss: 0.4019\n",
      "\n",
      "Epoch 00484: loss did not improve from 0.40150\n",
      "Epoch 485/500\n",
      "479947/479947 [==============================] - 194s 405us/step - loss: 0.4024\n",
      "\n",
      "Epoch 00485: loss did not improve from 0.40150\n",
      "Epoch 486/500\n",
      "479947/479947 [==============================] - 193s 402us/step - loss: 0.4020\n",
      "\n",
      "Epoch 00486: loss did not improve from 0.40150\n",
      "Epoch 487/500\n",
      "479947/479947 [==============================] - 194s 405us/step - loss: 0.4021\n",
      "\n",
      "Epoch 00487: loss did not improve from 0.40150\n",
      "Epoch 488/500\n",
      "479947/479947 [==============================] - 197s 411us/step - loss: 0.4019\n",
      "\n",
      "Epoch 00488: loss did not improve from 0.40150\n",
      "Epoch 489/500\n",
      "479947/479947 [==============================] - 196s 408us/step - loss: 0.4016\n",
      "\n",
      "Epoch 00489: loss did not improve from 0.40150\n",
      "Epoch 490/500\n",
      "479947/479947 [==============================] - 193s 401us/step - loss: 0.4020\n",
      "\n",
      "Epoch 00490: loss did not improve from 0.40150\n",
      "Epoch 491/500\n",
      "479947/479947 [==============================] - 194s 405us/step - loss: 0.4017\n",
      "\n",
      "Epoch 00491: loss did not improve from 0.40150\n",
      "Epoch 492/500\n",
      "479947/479947 [==============================] - 194s 404us/step - loss: 0.4022\n",
      "\n",
      "Epoch 00492: loss did not improve from 0.40150\n",
      "Epoch 493/500\n",
      "479947/479947 [==============================] - 196s 408us/step - loss: 0.4017\n",
      "\n",
      "Epoch 00493: loss did not improve from 0.40150\n",
      "Epoch 494/500\n",
      "479947/479947 [==============================] - 196s 409us/step - loss: 0.4010\n",
      "\n",
      "Epoch 00494: loss improved from 0.40150 to 0.40099, saving model to weights/weights-improvement-494-0.4010.hdf5\n",
      "Epoch 495/500\n",
      "479947/479947 [==============================] - 194s 404us/step - loss: 0.4019\n",
      "\n",
      "Epoch 00495: loss did not improve from 0.40099\n",
      "Epoch 496/500\n",
      "479947/479947 [==============================] - 195s 406us/step - loss: 0.4018\n",
      "\n",
      "Epoch 00496: loss did not improve from 0.40099\n",
      "Epoch 497/500\n",
      "479947/479947 [==============================] - 196s 408us/step - loss: 0.4014\n",
      "\n",
      "Epoch 00497: loss did not improve from 0.40099\n",
      "Epoch 498/500\n",
      "479947/479947 [==============================] - 194s 405us/step - loss: 0.4014\n",
      "\n",
      "Epoch 00498: loss did not improve from 0.40099\n",
      "Epoch 499/500\n",
      "479947/479947 [==============================] - 194s 405us/step - loss: 0.4011\n",
      "\n",
      "Epoch 00499: loss did not improve from 0.40099\n",
      "Epoch 500/500\n",
      "479947/479947 [==============================] - 195s 407us/step - loss: 0.4014\n",
      "\n",
      "Epoch 00500: loss did not improve from 0.40099\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c98a383e10>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the checkpoint\n",
    "filepath=\"weights/weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X, y, epochs=500, batch_size=128, callbacks=callbacks_list, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Image Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# load the network weights\n",
    "filename = \"weights/weights-improvement-287-0.4237.hdf5\"\n",
    "model.load_weights(filename)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "int_to_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "# pick a random seed\n",
    "start = np.random.randint(0, len(dataX)-1)\n",
    "pattern = dataX[start]\n",
    "seed = ' '.join([int_to_char[value] for value in pattern])\n",
    "\n",
    "# generate characters\n",
    "generated_image = \"\"\n",
    "for i in range(56 * 56):\n",
    "\tx = np.reshape(pattern, (1, len(pattern), 1))\n",
    "\tx = x / float(n_vocab)\n",
    "\tprediction = model.predict(x, verbose=0)\n",
    "\tindex = np.argmax(prediction)\n",
    "\tresult = int_to_char[index]\n",
    "\tseq_in = [int_to_char[value] for value in pattern]\n",
    "\tgenerated_image += result\n",
    "\tpattern.append(index)\n",
    "\tpattern = pattern[1:len(pattern)]\n",
    "    \n",
    "timestamp = time.time()\n",
    "f = open(\"generated_img_data/new_mon-{}.txt\".format(timestamp), \"w\")\n",
    "f.write(generated_image)\n",
    "f.close()\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Image from Image Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_colors = {3: (0,0,0), 2: (85,85,85), 1: (170,170,170), 0: (255,255,255)}\n",
    "img = Image.new('RGB', (56, 56), color = 'white')\n",
    "pixel_data = img.load()\n",
    "    \n",
    "for ix in range(len(generated_image)):\n",
    "    pixel_data[ix%56, ix//56] = int_colors[int(generated_image[ix])]\n",
    "img.save('generated_img/new_mon-{}.png'.format(timestamp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
